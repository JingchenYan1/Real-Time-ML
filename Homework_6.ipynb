{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRK88+Vn1TbiOQ/VrKNxH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JingchenYan1/Real-Time-ML/blob/main/Homework_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9asl7e1mf_M3",
        "outputId": "2a3da201-dbef-4f0f-e975-37cd79986ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 1 loss=3.9715 time=24.99s lr=9.8e-05\n",
            "         val_acc=14.54%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 2 loss=3.4429 time=23.99s lr=9.0e-05\n",
            "         val_acc=20.32%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 3 loss=3.1359 time=23.94s lr=7.9e-05\n",
            "         val_acc=25.08%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 4 loss=2.9220 time=23.62s lr=6.5e-05\n",
            "         val_acc=27.84%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 5 loss=2.7647 time=23.81s lr=5.0e-05\n",
            "         val_acc=29.63%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 6 loss=2.6469 time=23.88s lr=3.5e-05\n",
            "         val_acc=31.35%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 7 loss=2.5592 time=24.44s lr=2.1e-05\n",
            "         val_acc=32.51%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 8 loss=2.4931 time=23.84s lr=9.5e-06\n",
            "         val_acc=33.30%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 9 loss=2.4502 time=23.85s lr=2.4e-06\n",
            "         val_acc=33.87%\n",
            "ViT patch=4 emb=256 depth=4 heads=2 Epoch 10 loss=2.4245 time=23.91s lr=0.0e+00\n",
            "         val_acc=33.90%\n",
            "Config {'patch': 4, 'emb': 256, 'depth': 4, 'heads': 2, 'mlp': 512} params: 2164068\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 1 loss=3.7856 time=173.00s lr=9.8e-05\n",
            "         val_acc=17.78%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 2 loss=3.0613 time=172.57s lr=9.0e-05\n",
            "         val_acc=28.52%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 3 loss=2.6428 time=172.54s lr=7.9e-05\n",
            "         val_acc=33.13%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 4 loss=2.3373 time=173.03s lr=6.5e-05\n",
            "         val_acc=36.88%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 5 loss=2.0860 time=173.50s lr=5.0e-05\n",
            "         val_acc=39.94%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 6 loss=1.8593 time=173.23s lr=3.5e-05\n",
            "         val_acc=41.87%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 7 loss=1.6604 time=172.99s lr=2.1e-05\n",
            "         val_acc=45.04%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 8 loss=1.4932 time=172.72s lr=9.5e-06\n",
            "         val_acc=46.06%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 9 loss=1.3724 time=173.34s lr=2.4e-06\n",
            "         val_acc=46.60%\n",
            "ViT patch=4 emb=512 depth=8 heads=4 Epoch 10 loss=1.2980 time=173.32s lr=0.0e+00\n",
            "         val_acc=46.87%\n",
            "Config {'patch': 4, 'emb': 512, 'depth': 8, 'heads': 4, 'mlp': 2048} params: 25330276\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 1 loss=3.9503 time=30.10s lr=9.8e-05\n",
            "         val_acc=14.47%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 2 loss=3.4222 time=29.13s lr=9.0e-05\n",
            "         val_acc=20.68%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 3 loss=3.0642 time=29.16s lr=7.9e-05\n",
            "         val_acc=25.57%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 4 loss=2.8044 time=28.71s lr=6.5e-05\n",
            "         val_acc=28.50%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 5 loss=2.6040 time=29.15s lr=5.0e-05\n",
            "         val_acc=31.22%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 6 loss=2.4380 time=29.32s lr=3.5e-05\n",
            "         val_acc=32.95%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 7 loss=2.2992 time=28.74s lr=2.1e-05\n",
            "         val_acc=33.77%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 8 loss=2.1910 time=29.41s lr=9.5e-06\n",
            "         val_acc=34.87%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 9 loss=2.1162 time=28.78s lr=2.4e-06\n",
            "         val_acc=35.09%\n",
            "ViT patch=8 emb=256 depth=8 heads=4 Epoch 10 loss=2.0726 time=29.18s lr=0.0e+00\n",
            "         val_acc=35.53%\n",
            "Config {'patch': 8, 'emb': 256, 'depth': 8, 'heads': 4, 'mlp': 1024} params: 6398308\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 1 loss=3.8922 time=22.55s lr=9.8e-05\n",
            "         val_acc=15.20%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 2 loss=3.3521 time=21.83s lr=9.0e-05\n",
            "         val_acc=21.67%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 3 loss=3.0134 time=21.95s lr=7.9e-05\n",
            "         val_acc=26.63%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 4 loss=2.7542 time=21.76s lr=6.5e-05\n",
            "         val_acc=27.82%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 5 loss=2.5560 time=21.79s lr=5.0e-05\n",
            "         val_acc=30.49%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 6 loss=2.3801 time=21.83s lr=3.5e-05\n",
            "         val_acc=32.05%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 7 loss=2.2318 time=21.67s lr=2.1e-05\n",
            "         val_acc=33.48%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 8 loss=2.1134 time=22.10s lr=9.5e-06\n",
            "         val_acc=33.89%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 9 loss=2.0268 time=21.51s lr=2.4e-06\n",
            "         val_acc=34.61%\n",
            "ViT patch=8 emb=512 depth=4 heads=2 Epoch 10 loss=1.9779 time=21.50s lr=0.0e+00\n",
            "         val_acc=34.57%\n",
            "Config {'patch': 8, 'emb': 512, 'depth': 4, 'heads': 2, 'mlp': 1024} params: 8571492\n",
            "ResNet18 Epoch 1 loss=3.6922 time=19.83s lr=9.8e-05\n",
            "          val_acc=22.25%\n",
            "ResNet18 Epoch 2 loss=2.9193 time=19.83s lr=9.0e-05\n",
            "          val_acc=28.54%\n",
            "ResNet18 Epoch 3 loss=2.4966 time=20.27s lr=7.9e-05\n",
            "          val_acc=32.42%\n",
            "ResNet18 Epoch 4 loss=2.1135 time=21.89s lr=6.5e-05\n",
            "          val_acc=33.86%\n",
            "ResNet18 Epoch 5 loss=1.7307 time=20.66s lr=5.0e-05\n",
            "          val_acc=35.25%\n",
            "ResNet18 Epoch 6 loss=1.3555 time=20.72s lr=3.5e-05\n",
            "          val_acc=35.31%\n",
            "ResNet18 Epoch 7 loss=1.0222 time=20.32s lr=2.1e-05\n",
            "          val_acc=34.54%\n",
            "ResNet18 Epoch 8 loss=0.7705 time=20.23s lr=9.5e-06\n",
            "          val_acc=34.89%\n",
            "ResNet18 Epoch 9 loss=0.6073 time=20.19s lr=2.4e-06\n",
            "          val_acc=34.71%\n",
            "ResNet18 Epoch 10 loss=0.5258 time=20.23s lr=0.0e+00\n",
            "          val_acc=34.64%\n",
            "ResNet18 params: 11227812\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import time\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self,img_size,patch_size,emb_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches=(img_size//patch_size)**2\n",
        "        self.proj=nn.Conv2d(3,emb_dim,patch_size,patch_size)\n",
        "    def forward(self,x):\n",
        "        x=self.proj(x)\n",
        "        x=x.flatten(2)\n",
        "        return x.transpose(1,2)\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self,emb_dim,heads,mlp_dim,drop_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.norm1=nn.LayerNorm(emb_dim)\n",
        "        self.attn=nn.MultiheadAttention(emb_dim,heads)\n",
        "        self.norm2=nn.LayerNorm(emb_dim)\n",
        "        self.mlp=nn.Sequential(\n",
        "            nn.Linear(emb_dim,mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(mlp_dim,emb_dim),\n",
        "            nn.Dropout(drop_rate),\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x2=x\n",
        "        x=x.transpose(0,1)\n",
        "        attn_out,_=self.attn(x,x,x)\n",
        "        x=(attn_out+x).transpose(0,1)\n",
        "        x=self.norm1(x)\n",
        "        x2=x\n",
        "        x=self.mlp(x)\n",
        "        x=self.norm2(x+x2)\n",
        "        return x\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self,img_size,patch_size,emb_dim,depth,heads,mlp_dim,n_classes,drop_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.patch=PatchEmbed(img_size,patch_size,emb_dim)\n",
        "        self.cls_token=nn.Parameter(torch.zeros(1,1,emb_dim))\n",
        "        self.pos_embed=nn.Parameter(torch.zeros(1,self.patch.num_patches+1,emb_dim))\n",
        "        self.blocks=nn.ModuleList([\n",
        "            TransformerEncoderBlock(emb_dim,heads,mlp_dim,drop_rate)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "        self.norm=nn.LayerNorm(emb_dim)\n",
        "        self.head=nn.Linear(emb_dim,n_classes)\n",
        "    def forward(self,x):\n",
        "        x=self.patch(x)\n",
        "        b=x.shape[0]\n",
        "        cls=self.cls_token.expand(b,-1,-1)\n",
        "        x=torch.cat((cls,x),1)\n",
        "        x+=self.pos_embed\n",
        "        for blk in self.blocks:\n",
        "            x=blk(x)\n",
        "        x=self.norm(x[:,0])\n",
        "        return self.head(x)\n",
        "\n",
        "def train_epoch(model,loader,optim,device):\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "    for xb,yb in loader:\n",
        "        xb,yb=xb.to(device),yb.to(device)\n",
        "        out=model(xb)\n",
        "        loss=nn.CrossEntropyLoss()(out,yb)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
        "        optim.step()\n",
        "        total_loss+=loss.item()*xb.size(0)\n",
        "    return total_loss/len(loader.dataset)\n",
        "\n",
        "def test(model,loader,device):\n",
        "    model.eval()\n",
        "    correct=0\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in loader:\n",
        "            xb,yb=xb.to(device),yb.to(device)\n",
        "            out=model(xb)\n",
        "            correct+=(out.argmax(1)==yb).sum().item()\n",
        "    return correct/len(loader.dataset)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071,0.4865,0.4409),(0.2673,0.2564,0.2761))\n",
        "])\n",
        "trainset=datasets.CIFAR100(root='./data',train=True,download=True,transform=transform)\n",
        "testset=datasets.CIFAR100(root='./data',train=False,download=True,transform=transform)\n",
        "trainloader=DataLoader(trainset,batch_size=64,shuffle=True,num_workers=2)\n",
        "testloader=DataLoader(testset,batch_size=64,shuffle=False,num_workers=2)\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "configs=[\n",
        "    {'patch':4,'emb':256,'depth':4,'heads':2,'mlp':512},\n",
        "    {'patch':4,'emb':512,'depth':8,'heads':4,'mlp':2048},\n",
        "    {'patch':8,'emb':256,'depth':8,'heads':4,'mlp':1024},\n",
        "    {'patch':8,'emb':512,'depth':4,'heads':2,'mlp':1024}\n",
        "]\n",
        "\n",
        "for cfg in configs:\n",
        "    model=ViT(32,cfg['patch'],cfg['emb'],cfg['depth'],cfg['heads'],cfg['mlp'],100,drop_rate=0.1).to(device)\n",
        "    optimizer=optim.Adam(model.parameters(),lr=1e-4,weight_decay=1e-4)\n",
        "    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)\n",
        "    for epoch in range(10):\n",
        "        t0=time.time()\n",
        "        loss=train_epoch(model,trainloader,optimizer,device)\n",
        "        t1=time.time()\n",
        "        scheduler.step()\n",
        "        print(f\"ViT patch={cfg['patch']} emb={cfg['emb']} depth={cfg['depth']} heads={cfg['heads']} Epoch {epoch+1} loss={loss:.4f} time={(t1-t0):.2f}s lr={scheduler.get_last_lr()[0]:.1e}\")\n",
        "        acc=test(model,testloader,device)\n",
        "        print(f\"         val_acc={acc*100:.2f}%\")\n",
        "    params=sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Config {cfg} params: {params}\")\n",
        "\n",
        "resnet=models.resnet18(num_classes=100).to(device)\n",
        "optimizer=optim.Adam(resnet.parameters(),lr=1e-4,weight_decay=1e-4)\n",
        "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)\n",
        "for epoch in range(10):\n",
        "    t0=time.time()\n",
        "    loss=train_epoch(resnet,trainloader,optimizer,device)\n",
        "    t1=time.time()\n",
        "    scheduler.step()\n",
        "    print(f\"ResNet18 Epoch {epoch+1} loss={loss:.4f} time={(t1-t0):.2f}s lr={scheduler.get_last_lr()[0]:.1e}\")\n",
        "    acc=test(resnet,testloader,device)\n",
        "    print(f\"          val_acc={acc*100:.2f}%\")\n",
        "params=sum(p.numel() for p in resnet.parameters())\n",
        "print(f\"ResNet18 params: {params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import SwinForImageClassification, SwinConfig, AutoFeatureExtractor\n",
        "import time\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained('microsoft/swin-tiny-patch4-window7-224')\n",
        "mean = feature_extractor.image_mean\n",
        "std = feature_extractor.image_std\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "epochs = 5\n",
        "lr = 2e-5\n",
        "results = []\n",
        "\n",
        "# Load pretrained Tiny and Small, replace head, freeze backbone\n",
        "tiny_ft = SwinForImageClassification.from_pretrained('microsoft/swin-tiny-patch4-window7-224')\n",
        "tiny_ft.classifier = nn.Linear(tiny_ft.config.hidden_size, 100)\n",
        "for name, param in tiny_ft.named_parameters():\n",
        "    if 'classifier' not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "small_ft = SwinForImageClassification.from_pretrained('microsoft/swin-small-patch4-window7-224')\n",
        "small_ft.classifier = nn.Linear(small_ft.config.hidden_size, 100)\n",
        "for name, param in small_ft.named_parameters():\n",
        "    if 'classifier' not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "config = SwinConfig.from_pretrained('microsoft/swin-tiny-patch4-window7-224')\n",
        "config.num_labels = 100\n",
        "town_scratch = SwinForImageClassification(config)\n",
        "\n",
        "models = {\n",
        "    'swin-tiny-ft': tiny_ft,\n",
        "    'swin-small-ft': small_ft,\n",
        "    'swin-tiny-scratch': town_scratch\n",
        "}\n",
        "\n",
        "for key, model in models.items():\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "    print(f\"\\nStarting fine-tune/train for {key}\")\n",
        "    for epoch in range(epochs):\n",
        "        t0 = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xb, yb in trainloader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb).logits\n",
        "            loss = nn.CrossEntropyLoss()(logits, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "        train_loss = total_loss / len(trainset)\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in testloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                preds = model(xb).logits.argmax(dim=1)\n",
        "                correct += (preds == yb).sum().item()\n",
        "        val_acc = correct / len(testset)\n",
        "        t1 = time.time()\n",
        "        print(f\"{key} Epoch {epoch+1}/{epochs} train_loss={train_loss:.4f} val_acc={val_acc*100:.2f}% time={(t1-t0):.2f}s\")\n",
        "    # Final metrics\n",
        "    params = sum(p.numel() for p in model.parameters())\n",
        "    time_per_epoch = (t1 - t0)\n",
        "    results.append((key, params, time_per_epoch, val_acc))\n",
        "\n",
        "print('\\nSummary Results:')\n",
        "for r in results:\n",
        "    print(r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw_K6NpDhPDb",
        "outputId": "608ae43c-c310-419c-b1f8-aa4336fe68cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting fine-tune/train for swin-tiny-ft\n",
            "swin-tiny-ft Epoch 1/5 train_loss=4.0374 val_acc=46.20% time=280.79s\n",
            "swin-tiny-ft Epoch 2/5 train_loss=3.0465 val_acc=57.91% time=280.92s\n",
            "swin-tiny-ft Epoch 3/5 train_loss=2.3707 val_acc=62.31% time=280.72s\n",
            "swin-tiny-ft Epoch 4/5 train_loss=1.9424 val_acc=64.77% time=281.02s\n",
            "swin-tiny-ft Epoch 5/5 train_loss=1.6727 val_acc=66.27% time=280.65s\n",
            "\n",
            "Starting fine-tune/train for swin-small-ft\n",
            "swin-small-ft Epoch 1/5 train_loss=3.9802 val_acc=51.48% time=489.01s\n",
            "swin-small-ft Epoch 2/5 train_loss=2.8934 val_acc=62.52% time=489.19s\n",
            "swin-small-ft Epoch 3/5 train_loss=2.1735 val_acc=66.31% time=488.56s\n",
            "swin-small-ft Epoch 4/5 train_loss=1.7375 val_acc=68.60% time=488.54s\n",
            "swin-small-ft Epoch 5/5 train_loss=1.4785 val_acc=70.07% time=488.52s\n",
            "\n",
            "Starting fine-tune/train for swin-tiny-scratch\n",
            "swin-tiny-scratch Epoch 1/5 train_loss=3.9567 val_acc=15.88% time=676.44s\n",
            "swin-tiny-scratch Epoch 2/5 train_loss=3.3520 val_acc=23.39% time=672.35s\n",
            "swin-tiny-scratch Epoch 3/5 train_loss=2.9811 val_acc=29.12% time=676.04s\n",
            "swin-tiny-scratch Epoch 4/5 train_loss=2.6846 val_acc=33.34% time=677.97s\n",
            "swin-tiny-scratch Epoch 5/5 train_loss=2.4209 val_acc=37.57% time=678.50s\n",
            "\n",
            "Summary Results:\n",
            "('swin-tiny-ft', 27596254, 280.649982213974, 0.6627)\n",
            "('swin-small-ft', 48914158, 488.52472710609436, 0.7007)\n",
            "('swin-tiny-scratch', 27596254, 678.5014929771423, 0.3757)\n"
          ]
        }
      ]
    }
  ]
}