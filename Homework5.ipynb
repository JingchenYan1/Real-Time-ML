{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPoSL7GzSrwv3V7y3Zaifmf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JingchenYan1/Real-Time-ML/blob/main/Homework5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH2jUkeEY_jr",
        "outputId": "12f35cd7-5202-48f4-bd98-e436cad6ee76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Device： cuda\n",
            "\n",
            "==============================\n",
            "Train the Transformer model (sequence length = 10)\n",
            "Number of model parameters： 277548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Loss: 2.8174, Val Acc: 0.2152\n",
            "Epoch 2/20 - Loss: 2.3826, Val Acc: 0.3249\n",
            "Epoch 3/20 - Loss: 2.2072, Val Acc: 0.3207\n",
            "Epoch 4/20 - Loss: 2.0727, Val Acc: 0.3333\n",
            "Epoch 5/20 - Loss: 1.9281, Val Acc: 0.3586\n",
            "Epoch 6/20 - Loss: 1.8277, Val Acc: 0.3502\n",
            "Epoch 7/20 - Loss: 1.7012, Val Acc: 0.3924\n",
            "Epoch 8/20 - Loss: 1.5934, Val Acc: 0.3671\n",
            "Epoch 9/20 - Loss: 1.4615, Val Acc: 0.3713\n",
            "Epoch 10/20 - Loss: 1.3586, Val Acc: 0.4008\n",
            "Epoch 11/20 - Loss: 1.2562, Val Acc: 0.3544\n",
            "Epoch 12/20 - Loss: 1.1598, Val Acc: 0.3924\n",
            "Epoch 13/20 - Loss: 1.0823, Val Acc: 0.3502\n",
            "Epoch 14/20 - Loss: 0.9955, Val Acc: 0.3840\n",
            "Epoch 15/20 - Loss: 0.9451, Val Acc: 0.3671\n",
            "Epoch 16/20 - Loss: 0.8780, Val Acc: 0.3502\n",
            "Epoch 17/20 - Loss: 0.8578, Val Acc: 0.4008\n",
            "Epoch 18/20 - Loss: 0.7882, Val Acc: 0.3671\n",
            "Epoch 19/20 - Loss: 0.7312, Val Acc: 0.4135\n",
            "Epoch 20/20 - Loss: 0.6668, Val Acc: 0.4093\n",
            "sequence length 10 total training time: 19.00 秒\n",
            "\n",
            "==============================\n",
            "Train the Transformer model (sequence length = 20)\n",
            "Number of model parameters： 278828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Loss: 2.7914, Val Acc: 0.1822\n",
            "Epoch 2/20 - Loss: 2.4470, Val Acc: 0.2373\n",
            "Epoch 3/20 - Loss: 2.3253, Val Acc: 0.2415\n",
            "Epoch 4/20 - Loss: 2.2442, Val Acc: 0.2331\n",
            "Epoch 5/20 - Loss: 2.1696, Val Acc: 0.2458\n",
            "Epoch 6/20 - Loss: 2.1037, Val Acc: 0.2797\n",
            "Epoch 7/20 - Loss: 1.9844, Val Acc: 0.2712\n",
            "Epoch 8/20 - Loss: 1.8719, Val Acc: 0.2585\n",
            "Epoch 9/20 - Loss: 1.7603, Val Acc: 0.3305\n",
            "Epoch 10/20 - Loss: 1.6339, Val Acc: 0.3305\n",
            "Epoch 11/20 - Loss: 1.5283, Val Acc: 0.3220\n",
            "Epoch 12/20 - Loss: 1.3803, Val Acc: 0.3432\n",
            "Epoch 13/20 - Loss: 1.2796, Val Acc: 0.3475\n",
            "Epoch 14/20 - Loss: 1.1808, Val Acc: 0.3390\n",
            "Epoch 15/20 - Loss: 1.0637, Val Acc: 0.3475\n",
            "Epoch 16/20 - Loss: 1.0025, Val Acc: 0.3856\n",
            "Epoch 17/20 - Loss: 0.9638, Val Acc: 0.3856\n",
            "Epoch 18/20 - Loss: 0.8226, Val Acc: 0.3644\n",
            "Epoch 19/20 - Loss: 0.7354, Val Acc: 0.3898\n",
            "Epoch 20/20 - Loss: 0.7342, Val Acc: 0.3347\n",
            "sequence length 20 total training time: 8.73 秒\n",
            "\n",
            "==============================\n",
            "Train the Transformer model (sequence length = 30)\n",
            "Number of model parameters： 280108\n",
            "Epoch 1/20 - Loss: 2.8628, Val Acc: 0.2340\n",
            "Epoch 2/20 - Loss: 2.4604, Val Acc: 0.2170\n",
            "Epoch 3/20 - Loss: 2.3669, Val Acc: 0.2468\n",
            "Epoch 4/20 - Loss: 2.3042, Val Acc: 0.2468\n",
            "Epoch 5/20 - Loss: 2.2558, Val Acc: 0.2766\n",
            "Epoch 6/20 - Loss: 2.1959, Val Acc: 0.2766\n",
            "Epoch 7/20 - Loss: 2.1467, Val Acc: 0.2426\n",
            "Epoch 8/20 - Loss: 2.0760, Val Acc: 0.2596\n",
            "Epoch 9/20 - Loss: 1.9920, Val Acc: 0.2638\n",
            "Epoch 10/20 - Loss: 1.9487, Val Acc: 0.2255\n",
            "Epoch 11/20 - Loss: 1.8711, Val Acc: 0.2213\n",
            "Epoch 12/20 - Loss: 1.7739, Val Acc: 0.2851\n",
            "Epoch 13/20 - Loss: 1.6934, Val Acc: 0.2638\n",
            "Epoch 14/20 - Loss: 1.5789, Val Acc: 0.2511\n",
            "Epoch 15/20 - Loss: 1.4549, Val Acc: 0.3106\n",
            "Epoch 16/20 - Loss: 1.3492, Val Acc: 0.2809\n",
            "Epoch 17/20 - Loss: 1.2992, Val Acc: 0.3191\n",
            "Epoch 18/20 - Loss: 1.1927, Val Acc: 0.3149\n",
            "Epoch 19/20 - Loss: 1.0890, Val Acc: 0.3234\n",
            "Epoch 20/20 - Loss: 1.0065, Val Acc: 0.3191\n",
            "sequence length 30 total training time: 8.76 秒\n",
            "\n",
            "==============================\n",
            "Training RNN model (LSTM without attention) (sequence length = 20)\n",
            "Number of RNN model parameters： 143404\n",
            "Epoch 1/20 - Loss: 3.0695, Val Acc: 0.2542\n",
            "Epoch 2/20 - Loss: 2.4840, Val Acc: 0.3983\n",
            "Epoch 3/20 - Loss: 2.2330, Val Acc: 0.4449\n",
            "Epoch 4/20 - Loss: 2.0483, Val Acc: 0.4576\n",
            "Epoch 5/20 - Loss: 1.9064, Val Acc: 0.4746\n",
            "Epoch 6/20 - Loss: 1.7694, Val Acc: 0.4746\n",
            "Epoch 7/20 - Loss: 1.6648, Val Acc: 0.5042\n",
            "Epoch 8/20 - Loss: 1.5599, Val Acc: 0.5212\n",
            "Epoch 9/20 - Loss: 1.4568, Val Acc: 0.5297\n",
            "Epoch 10/20 - Loss: 1.3662, Val Acc: 0.5339\n",
            "Epoch 11/20 - Loss: 1.2889, Val Acc: 0.5381\n",
            "Epoch 12/20 - Loss: 1.2113, Val Acc: 0.5466\n",
            "Epoch 13/20 - Loss: 1.1274, Val Acc: 0.5720\n",
            "Epoch 14/20 - Loss: 1.0591, Val Acc: 0.5593\n",
            "Epoch 15/20 - Loss: 0.9976, Val Acc: 0.5551\n",
            "Epoch 16/20 - Loss: 0.9226, Val Acc: 0.5720\n",
            "Epoch 17/20 - Loss: 0.8735, Val Acc: 0.5424\n",
            "Epoch 18/20 - Loss: 0.8067, Val Acc: 0.5551\n",
            "Epoch 19/20 - Loss: 0.7439, Val Acc: 0.5763\n",
            "Epoch 20/20 - Loss: 0.6894, Val Acc: 0.5593\n",
            "\n",
            "==============================\n",
            "Training RNN model with attention mechanism (sequence length = 20)\n",
            "RNN + Attention Number of model parameters： 143533\n",
            "Epoch 1/20 - Loss: 3.1973, Val Acc: 0.1483\n",
            "Epoch 2/20 - Loss: 3.0278, Val Acc: 0.1525\n",
            "Epoch 3/20 - Loss: 3.0078, Val Acc: 0.1483\n",
            "Epoch 4/20 - Loss: 2.9798, Val Acc: 0.1525\n",
            "Epoch 5/20 - Loss: 2.9516, Val Acc: 0.1610\n",
            "Epoch 6/20 - Loss: 2.9134, Val Acc: 0.1483\n",
            "Epoch 7/20 - Loss: 2.8476, Val Acc: 0.1780\n",
            "Epoch 8/20 - Loss: 2.7424, Val Acc: 0.1992\n",
            "Epoch 9/20 - Loss: 2.6004, Val Acc: 0.2500\n",
            "Epoch 10/20 - Loss: 2.4279, Val Acc: 0.2627\n",
            "Epoch 11/20 - Loss: 2.2258, Val Acc: 0.3347\n",
            "Epoch 12/20 - Loss: 2.0380, Val Acc: 0.3517\n",
            "Epoch 13/20 - Loss: 1.8688, Val Acc: 0.3814\n",
            "Epoch 14/20 - Loss: 1.7302, Val Acc: 0.4195\n",
            "Epoch 15/20 - Loss: 1.5962, Val Acc: 0.4280\n",
            "Epoch 16/20 - Loss: 1.4837, Val Acc: 0.3941\n",
            "Epoch 17/20 - Loss: 1.3688, Val Acc: 0.4110\n",
            "Epoch 18/20 - Loss: 1.2793, Val Acc: 0.4449\n",
            "Epoch 19/20 - Loss: 1.1717, Val Acc: 0.4407\n",
            "Epoch 20/20 - Loss: 1.0862, Val Acc: 0.4492\n",
            "\n",
            "==============================\n",
            "Summary of training results：\n",
            "Transformer (sequence length 10) - final training loss: 0.6668, Final verification accuracy: 0.4093, training time: 19.00s, Parameter quantity: 277548\n",
            "Transformer (sequence length 20) - final training loss: 0.7342, Final verification accuracy: 0.3347, training time: 8.73s, Parameter quantity: 278828\n",
            "Transformer (sequence length 30) - final training loss: 1.0065, Final verification accuracy: 0.3191, training time: 8.76s, Parameter quantity: 280108\n",
            "RNN (without attention) - final training loss: 0.6894, Final verification accuracy: 0.5593, training time: 3.85s, Parameter quantity: 143404\n",
            "RNN (with attention) - final training loss: 1.0862, Final verification accuracy: 0.4492, training time: 4.09s, Parameter quantity: 143533\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, text, seq_length):\n",
        "\n",
        "        self.text = text\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.chars = sorted(list(set(text)))\n",
        "        self.vocab_size = len(self.chars)\n",
        "        self.char_to_idx = { ch:i for i, ch in enumerate(self.chars) }\n",
        "        self.idx_to_char = { i:ch for i, ch in enumerate(self.chars) }\n",
        "\n",
        "        self.data = [self.char_to_idx[c] for c in text]\n",
        "\n",
        "        self.input_seqs = []\n",
        "        self.targets = []\n",
        "        for i in range(len(self.data) - seq_length):\n",
        "            self.input_seqs.append(self.data[i:i+seq_length])\n",
        "            self.targets.append(self.data[i+seq_length])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.input_seqs[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "\n",
        "class TransformerLM(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dim_feedforward=256, max_seq_len=30):\n",
        "\n",
        "        super(TransformerLM, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embedding = nn.Parameter(torch.zeros(1, max_seq_len, d_model))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.token_embedding(x)  # [B, L, d_model]\n",
        "        emb = emb + self.pos_embedding[:, :emb.size(1), :]\n",
        "        emb = emb.transpose(0, 1)\n",
        "        transformer_out = self.transformer(emb)  # [L, B, d_model]\n",
        "        out = self.fc_out(transformer_out[-1])  # [B, vocab_size]\n",
        "        return out\n",
        "\n",
        "class RNNLM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=128, hidden_size=128, num_layers=1):\n",
        "        super(RNNLM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        # 使用 LSTM 层\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len]\n",
        "        emb = self.embedding(x)  # [B, L, embed_size]\n",
        "        out, _ = self.lstm(emb)  # out: [B, L, hidden_size]\n",
        "        out = self.fc(out[:, -1, :])  # [B, vocab_size]\n",
        "        return out\n",
        "\n",
        "class RNNAttentionLM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=128, hidden_size=128, num_layers=1):\n",
        "        super(RNNAttentionLM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attn = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)  # [B, L, embed_size]\n",
        "        lstm_out, _ = self.lstm(emb)  # lstm_out: [B, L, hidden_size]\n",
        "        attn_scores = self.attn(lstm_out)\n",
        "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
        "        context = torch.sum(attn_weights * lstm_out, dim=1)\n",
        "        out = self.fc(context)  # [B, vocab_size]\n",
        "        return out\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001, device='cpu'):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {'train_loss': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for x, target in train_loader:\n",
        "            x, target = x.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x)  # output shape: [B, vocab_size]\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for x, target in val_loader:\n",
        "                x, target = x.to(device), target.to(device)\n",
        "                output = model(x)\n",
        "                pred = output.argmax(dim=-1)\n",
        "                correct += (pred == target).sum().item()\n",
        "                total += target.size(0)\n",
        "        val_acc = correct / total\n",
        "\n",
        "        history['train_loss'].append(avg_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    text = (\n",
        "        \"Next character prediction is a fundamental task in the field of natural language processing (NLP) that involves \"\n",
        "        \"predicting the next character in a sequence of text based on the characters that precede it. This task is essential \"\n",
        "        \"for various applications, including text auto-completion, spell checking, and even in the development of sophisticated \"\n",
        "        \"AI models capable of generating human-like text. \"\n",
        "        \"At its core, next character prediction relies on statistical models or deep learning algorithms to analyze a given \"\n",
        "        \"sequence of text and predict which character is most likely to follow. These predictions are based on patterns and \"\n",
        "        \"relationships learned from large datasets of text during the training phase of the model. \"\n",
        "        \"One of the most popular approaches to next character prediction involves the use of Recurrent Neural Networks (RNNs), \"\n",
        "        \"and more specifically, a variant called Long Short-Term Memory (LSTM) networks. RNNs are particularly well-suited for \"\n",
        "        \"sequential data like text, as they can maintain information in 'memory' about previous characters to inform the prediction \"\n",
        "        \"of the next character. LSTM networks enhance this capability by being able to remember long-term dependencies, making them \"\n",
        "        \"even more effective for next character prediction tasks. \"\n",
        "        \"Training a model for next character prediction involves feeding it large amounts of text data, allowing it to learn the \"\n",
        "        \"probability of each character's appearance following a sequence of characters. During this training process, the model \"\n",
        "        \"adjusts its parameters to minimize the difference between its predictions and the actual outcomes, thus improving its \"\n",
        "        \"predictive accuracy over time. \"\n",
        "        \"Once trained, the model can be used to predict the next character in a given piece of text by considering the sequence \"\n",
        "        \"of characters that precede it. This can enhance user experience in text editing software, improve efficiency in coding \"\n",
        "        \"environments with auto-completion features, and enable more natural interactions with AI-based chatbots and virtual assistants. \"\n",
        "        \"In summary, next character prediction plays a crucial role in enhancing the capabilities of various NLP applications, making \"\n",
        "        \"text-based interactions more efficient, accurate, and human-like. Through the use of advanced machine learning models like RNNs \"\n",
        "        \"and LSTMs, next character prediction continues to evolve, opening new possibilities for the future of text-based technology.\"\n",
        "    )\n",
        "\n",
        "    seq_lengths = [10, 20, 30]\n",
        "    transformer_results = {}\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Current Device：\", device)\n",
        "\n",
        "    for seq_length in seq_lengths:\n",
        "        print(\"\\n==============================\")\n",
        "        print(f\"Train the Transformer model (sequence length = {seq_length})\")\n",
        "        dataset = CharDataset(text, seq_length)\n",
        "        val_size = int(0.1 * len(dataset))\n",
        "        train_size = len(dataset) - val_size\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "        model = TransformerLM(vocab_size=dataset.vocab_size, max_seq_len=seq_length)\n",
        "        print(\"Number of model parameters：\", sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "        start_time = time.time()\n",
        "        history = train_model(model, train_loader, val_loader, num_epochs=20, lr=0.001, device=device)\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        transformer_results[seq_length] = {\n",
        "            \"history\": history,\n",
        "            \"time\": elapsed,\n",
        "            \"model_params\": sum(p.numel() for p in model.parameters())\n",
        "        }\n",
        "        print(f\"sequence length {seq_length} total training time: {elapsed:.2f} 秒\")\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"Training RNN model (LSTM without attention) (sequence length = 20)\")\n",
        "    dataset_rnn = CharDataset(text, seq_length=20)\n",
        "    val_size = int(0.1 * len(dataset_rnn))\n",
        "    train_size = len(dataset_rnn) - val_size\n",
        "    train_dataset_rnn, val_dataset_rnn = random_split(dataset_rnn, [train_size, val_size])\n",
        "    train_loader_rnn = DataLoader(train_dataset_rnn, batch_size=32, shuffle=True)\n",
        "    val_loader_rnn = DataLoader(val_dataset_rnn, batch_size=32)\n",
        "\n",
        "    rnn_model = RNNLM(vocab_size=dataset_rnn.vocab_size)\n",
        "    print(\"Number of RNN model parameters：\", sum(p.numel() for p in rnn_model.parameters()))\n",
        "    start_time = time.time()\n",
        "    history_rnn = train_model(rnn_model, train_loader_rnn, val_loader_rnn, num_epochs=20, lr=0.001, device=device)\n",
        "    elapsed_rnn = time.time() - start_time\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"Training RNN model with attention mechanism (sequence length = 20)\")\n",
        "    rnn_att_model = RNNAttentionLM(vocab_size=dataset_rnn.vocab_size)\n",
        "    print(\"RNN + Attention Number of model parameters：\", sum(p.numel() for p in rnn_att_model.parameters()))\n",
        "    start_time = time.time()\n",
        "    history_rnn_att = train_model(rnn_att_model, train_loader_rnn, val_loader_rnn, num_epochs=20, lr=0.001, device=device)\n",
        "    elapsed_rnn_att = time.time() - start_time\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"Summary of training results：\")\n",
        "    for seq_length, res in transformer_results.items():\n",
        "        print(f\"Transformer (sequence length {seq_length}) - final training loss: {res['history']['train_loss'][-1]:.4f}, Final verification accuracy: {res['history']['val_acc'][-1]:.4f}, training time: {res['time']:.2f}s, Parameter quantity: {res['model_params']}\")\n",
        "    print(f\"RNN (without attention) - final training loss: {history_rnn['train_loss'][-1]:.4f}, Final verification accuracy: {history_rnn['val_acc'][-1]:.4f}, training time: {elapsed_rnn:.2f}s, Parameter quantity: {sum(p.numel() for p in rnn_model.parameters())}\")\n",
        "    print(f\"RNN (with attention) - final training loss: {history_rnn_att['train_loss'][-1]:.4f}, Final verification accuracy: {history_rnn_att['val_acc'][-1]:.4f}, training time: {elapsed_rnn_att:.2f}s, Parameter quantity: {sum(p.numel() for p in rnn_att_model.parameters())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import time\n",
        "import math\n",
        "import requests\n",
        "\n",
        "def get_data_loaders(seq_length, batch_size=128):\n",
        "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "    response = requests.get(url)\n",
        "    text = response.text\n",
        "\n",
        "    chars = sorted(list(set(text)))\n",
        "    char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "    int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "    encoded_text = [char_to_int[ch] for ch in text]\n",
        "\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(0, len(encoded_text) - seq_length):\n",
        "        seq = encoded_text[i:i+seq_length]\n",
        "        target = encoded_text[i+seq_length]\n",
        "        sequences.append(seq)\n",
        "        targets.append(target)\n",
        "\n",
        "    sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "    targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "    class CharDataset(Dataset):\n",
        "        def __init__(self, sequences, targets):\n",
        "            self.sequences = sequences\n",
        "            self.targets = targets\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.sequences)\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            return self.sequences[index], self.targets[index]\n",
        "\n",
        "    dataset = CharDataset(sequences, targets)\n",
        "\n",
        "    train_size = int(len(dataset) * 0.8)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader, len(chars)\n",
        "\n",
        "class TransformerLM(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, nhead=2, num_layers=2,\n",
        "                 dim_feedforward=256, max_seq_len=50):\n",
        "\n",
        "        super(TransformerLM, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embedding = nn.Parameter(torch.zeros(1, max_seq_len, d_model))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.token_embedding(x)  # [B, L, d_model]\n",
        "        emb = emb + self.pos_embedding[:, :emb.size(1), :]\n",
        "        emb = emb.transpose(0, 1)\n",
        "        transformer_out = self.transformer(emb)  # [L, B, d_model]\n",
        "        out = self.fc_out(transformer_out[-1])  # [B, vocab_size]\n",
        "        return out\n",
        "\n",
        "class RNNLM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=128, hidden_size=128, num_layers=1):\n",
        "        super(RNNLM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)  # [B, L, embed_size]\n",
        "        out, _ = self.lstm(emb)   # out: [B, L, hidden_size]\n",
        "        out = self.fc(out[:, -1, :])  # [B, vocab_size]\n",
        "        return out\n",
        "\n",
        "def train_model(model, train_loader, test_loader, num_epochs=10, lr=0.001, device='cpu'):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {'train_loss': [], 'test_acc': [], 'epoch_time': []}\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for x, target in train_loader:\n",
        "            x, target = x.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for x, target in test_loader:\n",
        "                x, target = x.to(device), target.to(device)\n",
        "                outputs = model(x)\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                correct += (predicted == target).sum().item()\n",
        "                total += target.size(0)\n",
        "        test_acc = correct / total\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        history['train_loss'].append(avg_loss)\n",
        "        history['test_acc'].append(test_acc)\n",
        "        history['epoch_time'].append(epoch_time)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}, Test Acc: {test_acc:.4f}, Time: {epoch_time:.2f}s\")\n",
        "    return history\n",
        "\n",
        "def get_model_size(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def compute_perplexity(loss):\n",
        "    return math.exp(loss)\n",
        "\n",
        "def run_transformer_experiments(seq_length, num_epochs=10, batch_size=128, device='cpu'):\n",
        "    print(f\"\\n=== Transformer Experiments | Sequence Length: {seq_length} ===\")\n",
        "    train_loader, test_loader, vocab_size = get_data_loaders(seq_length, batch_size)\n",
        "    results = {}\n",
        "    for num_layers in [1, 2, 4]:\n",
        "        for nhead in [2, 4]:\n",
        "            print(f\"\\nTransformer Model - Layers: {num_layers}, Heads: {nhead}\")\n",
        "            model = TransformerLM(vocab_size=vocab_size, d_model=128, nhead=nhead,\n",
        "                                  num_layers=num_layers, dim_feedforward=256, max_seq_len=seq_length)\n",
        "            param_count = get_model_size(model)\n",
        "            print(f\"Model Size: {param_count} parameters\")\n",
        "\n",
        "            start_time = time.time()\n",
        "            history = train_model(model, train_loader, test_loader, num_epochs=num_epochs, lr=0.001, device=device)\n",
        "            total_time = time.time() - start_time\n",
        "\n",
        "            final_loss = history['train_loss'][-1]\n",
        "            final_test_acc = history['test_acc'][-1]\n",
        "            perplexity = compute_perplexity(final_loss)\n",
        "            avg_epoch_time = sum(history['epoch_time']) / len(history['epoch_time'])\n",
        "\n",
        "            results[(num_layers, nhead)] = {\n",
        "                'final_loss': final_loss,\n",
        "                'final_test_acc': final_test_acc,\n",
        "                'perplexity': perplexity,\n",
        "                'avg_epoch_time': avg_epoch_time,\n",
        "                'total_time': total_time,\n",
        "                'model_size': param_count\n",
        "            }\n",
        "    return results\n",
        "\n",
        "def run_rnn_experiment(seq_length, num_epochs=10, batch_size=128, device='cpu'):\n",
        "    print(f\"\\n=== RNN Experiment | Sequence Length: {seq_length} ===\")\n",
        "    train_loader, test_loader, vocab_size = get_data_loaders(seq_length, batch_size)\n",
        "    model = RNNLM(vocab_size=vocab_size, embed_size=128, hidden_size=128, num_layers=1)\n",
        "    param_count = get_model_size(model)\n",
        "    print(f\"RNN Model Size: {param_count} parameters\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = train_model(model, train_loader, test_loader, num_epochs=num_epochs, lr=0.001, device=device)\n",
        "    total_time = time.time() - start_time\n",
        "    final_loss = history['train_loss'][-1]\n",
        "    final_test_acc = history['test_acc'][-1]\n",
        "    perplexity = compute_perplexity(final_loss)\n",
        "    avg_epoch_time = sum(history['epoch_time']) / len(history['epoch_time'])\n",
        "\n",
        "    results = {\n",
        "        'final_loss': final_loss,\n",
        "        'final_test_acc': final_test_acc,\n",
        "        'perplexity': perplexity,\n",
        "        'avg_epoch_time': avg_epoch_time,\n",
        "        'total_time': total_time,\n",
        "        'model_size': param_count\n",
        "    }\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "    num_epochs = 10\n",
        "    batch_size = 128\n",
        "\n",
        "    transformer_results_20 = run_transformer_experiments(seq_length=20, num_epochs=num_epochs, batch_size=batch_size, device=device)\n",
        "    transformer_results_30 = run_transformer_experiments(seq_length=30, num_epochs=num_epochs, batch_size=batch_size, device=device)\n",
        "    transformer_results_50 = run_transformer_experiments(seq_length=50, num_epochs=num_epochs, batch_size=batch_size, device=device)\n",
        "\n",
        "    rnn_results_20 = run_rnn_experiment(seq_length=20, num_epochs=num_epochs, batch_size=batch_size, device=device)\n",
        "    rnn_results_30 = run_rnn_experiment(seq_length=30, num_epochs=num_epochs, batch_size=batch_size, device=device)\n",
        "\n",
        "    print(\"\\n=== Summary of Transformer Experiments (Sequence Length 20) ===\")\n",
        "    for (num_layers, nhead), res in transformer_results_20.items():\n",
        "        print(f\"Layers: {num_layers}, Heads: {nhead} -> Loss: {res['final_loss']:.4f}, Test Acc: {res['final_test_acc']:.4f}, \"\n",
        "              f\"Perplexity: {res['perplexity']:.4f}, Avg Epoch Time: {res['avg_epoch_time']:.2f}s, Total Time: {res['total_time']:.2f}s, \"\n",
        "              f\"Model Size: {res['model_size']}\")\n",
        "\n",
        "    print(\"\\n=== Summary of Transformer Experiments (Sequence Length 30) ===\")\n",
        "    for (num_layers, nhead), res in transformer_results_30.items():\n",
        "        print(f\"Layers: {num_layers}, Heads: {nhead} -> Loss: {res['final_loss']:.4f}, Test Acc: {res['final_test_acc']:.4f}, \"\n",
        "              f\"Perplexity: {res['perplexity']:.4f}, Avg Epoch Time: {res['avg_epoch_time']:.2f}s, Total Time: {res['total_time']:.2f}s, \"\n",
        "              f\"Model Size: {res['model_size']}\")\n",
        "\n",
        "    print(\"\\n=== Summary of Transformer Experiments (Sequence Length 50) ===\")\n",
        "    for (num_layers, nhead), res in transformer_results_50.items():\n",
        "        print(f\"Layers: {num_layers}, Heads: {nhead} -> Loss: {res['final_loss']:.4f}, Test Acc: {res['final_test_acc']:.4f}, \"\n",
        "              f\"Perplexity: {res['perplexity']:.4f}, Avg Epoch Time: {res['avg_epoch_time']:.2f}s, Total Time: {res['total_time']:.2f}s, \"\n",
        "              f\"Model Size: {res['model_size']}\")\n",
        "\n",
        "    print(\"\\n=== Summary of RNN Experiments ===\")\n",
        "    print(f\"RNN (Sequence Length 20) -> Loss: {rnn_results_20['final_loss']:.4f}, Test Acc: {rnn_results_20['final_test_acc']:.4f}, \"\n",
        "          f\"Perplexity: {rnn_results_20['perplexity']:.4f}, Avg Epoch Time: {rnn_results_20['avg_epoch_time']:.2f}s, \"\n",
        "          f\"Total Time: {rnn_results_20['total_time']:.2f}s, Model Size: {rnn_results_20['model_size']}\")\n",
        "    print(f\"RNN (Sequence Length 30) -> Loss: {rnn_results_30['final_loss']:.4f}, Test Acc: {rnn_results_30['final_test_acc']:.4f}, \"\n",
        "          f\"Perplexity: {rnn_results_30['perplexity']:.4f}, Avg Epoch Time: {rnn_results_30['avg_epoch_time']:.2f}s, \"\n",
        "          f\"Total Time: {rnn_results_30['total_time']:.2f}s, Model Size: {rnn_results_30['model_size']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4o1tjIgdKTR",
        "outputId": "2bd07311-d07c-43f0-89a4-7428910c3eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== Transformer Experiments | Sequence Length: 20 ===\n",
            "\n",
            "Transformer Model - Layers: 1, Heads: 2\n",
            "Model Size: 151745 parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 2.0600, Test Acc: 0.4521, Time: 34.68s\n",
            "Epoch 2/10 - Loss: 1.8860, Test Acc: 0.4647, Time: 34.76s\n",
            "Epoch 3/10 - Loss: 1.8518, Test Acc: 0.4684, Time: 34.02s\n",
            "Epoch 4/10 - Loss: 1.8336, Test Acc: 0.4738, Time: 34.85s\n",
            "Epoch 5/10 - Loss: 1.8221, Test Acc: 0.4709, Time: 34.44s\n",
            "Epoch 6/10 - Loss: 1.8131, Test Acc: 0.4769, Time: 33.78s\n",
            "Epoch 7/10 - Loss: 1.8068, Test Acc: 0.4801, Time: 34.16s\n",
            "Epoch 8/10 - Loss: 1.8021, Test Acc: 0.4780, Time: 34.22s\n",
            "Epoch 9/10 - Loss: 1.7997, Test Acc: 0.4785, Time: 34.04s\n",
            "Epoch 10/10 - Loss: 1.7938, Test Acc: 0.4818, Time: 34.13s\n",
            "\n",
            "Transformer Model - Layers: 1, Heads: 4\n",
            "Model Size: 151745 parameters\n",
            "Epoch 1/10 - Loss: 2.0161, Test Acc: 0.4680, Time: 34.95s\n",
            "Epoch 2/10 - Loss: 1.8195, Test Acc: 0.4850, Time: 33.81s\n",
            "Epoch 3/10 - Loss: 1.7793, Test Acc: 0.4907, Time: 34.01s\n",
            "Epoch 4/10 - Loss: 1.7592, Test Acc: 0.4965, Time: 34.40s\n",
            "Epoch 5/10 - Loss: 1.7475, Test Acc: 0.4970, Time: 34.21s\n",
            "Epoch 6/10 - Loss: 1.7392, Test Acc: 0.4995, Time: 34.28s\n",
            "Epoch 7/10 - Loss: 1.7319, Test Acc: 0.5004, Time: 34.23s\n",
            "Epoch 8/10 - Loss: 1.7270, Test Acc: 0.5019, Time: 34.88s\n",
            "Epoch 9/10 - Loss: 1.7244, Test Acc: 0.5012, Time: 33.98s\n",
            "Epoch 10/10 - Loss: 1.7203, Test Acc: 0.5038, Time: 33.81s\n",
            "\n",
            "Transformer Model - Layers: 2, Heads: 2\n",
            "Model Size: 284225 parameters\n",
            "Epoch 1/10 - Loss: 1.9881, Test Acc: 0.4755, Time: 49.28s\n",
            "Epoch 2/10 - Loss: 1.7817, Test Acc: 0.4924, Time: 49.44s\n",
            "Epoch 3/10 - Loss: 1.7341, Test Acc: 0.5026, Time: 48.92s\n",
            "Epoch 4/10 - Loss: 1.7082, Test Acc: 0.5065, Time: 49.50s\n",
            "Epoch 5/10 - Loss: 1.6908, Test Acc: 0.5120, Time: 48.99s\n",
            "Epoch 6/10 - Loss: 1.6782, Test Acc: 0.5149, Time: 48.81s\n",
            "Epoch 7/10 - Loss: 1.6684, Test Acc: 0.5158, Time: 48.80s\n",
            "Epoch 8/10 - Loss: 1.6615, Test Acc: 0.5175, Time: 48.99s\n",
            "Epoch 9/10 - Loss: 1.6547, Test Acc: 0.5194, Time: 49.66s\n",
            "Epoch 10/10 - Loss: 1.6508, Test Acc: 0.5194, Time: 48.99s\n",
            "\n",
            "Transformer Model - Layers: 2, Heads: 4\n",
            "Model Size: 284225 parameters\n",
            "Epoch 1/10 - Loss: 1.9589, Test Acc: 0.4840, Time: 49.25s\n",
            "Epoch 2/10 - Loss: 1.7435, Test Acc: 0.5013, Time: 49.35s\n",
            "Epoch 3/10 - Loss: 1.6966, Test Acc: 0.5100, Time: 49.06s\n",
            "Epoch 4/10 - Loss: 1.6713, Test Acc: 0.5121, Time: 49.53s\n",
            "Epoch 5/10 - Loss: 1.6550, Test Acc: 0.5170, Time: 49.27s\n",
            "Epoch 6/10 - Loss: 1.6416, Test Acc: 0.5208, Time: 49.08s\n",
            "Epoch 7/10 - Loss: 1.6313, Test Acc: 0.5259, Time: 49.04s\n",
            "Epoch 8/10 - Loss: 1.6234, Test Acc: 0.5279, Time: 49.52s\n",
            "Epoch 9/10 - Loss: 1.6170, Test Acc: 0.5268, Time: 48.95s\n",
            "Epoch 10/10 - Loss: 1.6123, Test Acc: 0.5290, Time: 49.44s\n",
            "\n",
            "Transformer Model - Layers: 4, Heads: 2\n",
            "Model Size: 549185 parameters\n",
            "Epoch 1/10 - Loss: 1.9616, Test Acc: 0.4807, Time: 78.44s\n",
            "Epoch 2/10 - Loss: 1.7486, Test Acc: 0.4984, Time: 79.13s\n",
            "Epoch 3/10 - Loss: 1.7013, Test Acc: 0.5038, Time: 78.28s\n",
            "Epoch 4/10 - Loss: 1.6734, Test Acc: 0.5127, Time: 78.66s\n",
            "Epoch 5/10 - Loss: 1.6532, Test Acc: 0.5152, Time: 78.91s\n",
            "Epoch 6/10 - Loss: 1.6388, Test Acc: 0.5194, Time: 78.55s\n",
            "Epoch 7/10 - Loss: 1.6273, Test Acc: 0.5210, Time: 77.95s\n",
            "Epoch 8/10 - Loss: 1.6162, Test Acc: 0.5246, Time: 79.19s\n",
            "Epoch 9/10 - Loss: 1.6094, Test Acc: 0.5250, Time: 78.72s\n",
            "Epoch 10/10 - Loss: 1.6018, Test Acc: 0.5260, Time: 77.93s\n",
            "\n",
            "Transformer Model - Layers: 4, Heads: 4\n",
            "Model Size: 549185 parameters\n",
            "Epoch 1/10 - Loss: 1.9373, Test Acc: 0.4855, Time: 82.05s\n",
            "Epoch 2/10 - Loss: 1.7214, Test Acc: 0.5052, Time: 81.38s\n",
            "Epoch 3/10 - Loss: 1.6746, Test Acc: 0.5098, Time: 80.85s\n",
            "Epoch 4/10 - Loss: 1.6487, Test Acc: 0.5196, Time: 81.25s\n",
            "Epoch 5/10 - Loss: 1.6307, Test Acc: 0.5245, Time: 80.72s\n",
            "Epoch 6/10 - Loss: 1.6170, Test Acc: 0.5255, Time: 80.65s\n",
            "Epoch 7/10 - Loss: 1.6067, Test Acc: 0.5274, Time: 80.59s\n",
            "Epoch 8/10 - Loss: 1.5972, Test Acc: 0.5274, Time: 80.61s\n",
            "Epoch 9/10 - Loss: 1.5897, Test Acc: 0.5332, Time: 80.81s\n",
            "Epoch 10/10 - Loss: 1.5832, Test Acc: 0.5324, Time: 81.28s\n",
            "\n",
            "=== Transformer Experiments | Sequence Length: 30 ===\n",
            "\n",
            "Transformer Model - Layers: 1, Heads: 2\n",
            "Model Size: 153025 parameters\n",
            "Epoch 1/10 - Loss: 2.0833, Test Acc: 0.4512, Time: 35.63s\n",
            "Epoch 2/10 - Loss: 1.8974, Test Acc: 0.4696, Time: 35.49s\n",
            "Epoch 3/10 - Loss: 1.8600, Test Acc: 0.4729, Time: 35.75s\n",
            "Epoch 4/10 - Loss: 1.8403, Test Acc: 0.4748, Time: 35.45s\n",
            "Epoch 5/10 - Loss: 1.8289, Test Acc: 0.4780, Time: 35.42s\n",
            "Epoch 6/10 - Loss: 1.8196, Test Acc: 0.4797, Time: 35.97s\n",
            "Epoch 7/10 - Loss: 1.8131, Test Acc: 0.4812, Time: 35.51s\n",
            "Epoch 8/10 - Loss: 1.8091, Test Acc: 0.4815, Time: 35.51s\n",
            "Epoch 9/10 - Loss: 1.8033, Test Acc: 0.4818, Time: 35.71s\n",
            "Epoch 10/10 - Loss: 1.7988, Test Acc: 0.4834, Time: 35.40s\n",
            "\n",
            "Transformer Model - Layers: 1, Heads: 4\n",
            "Model Size: 153025 parameters\n",
            "Epoch 1/10 - Loss: 2.0650, Test Acc: 0.4532, Time: 35.89s\n",
            "Epoch 2/10 - Loss: 1.8652, Test Acc: 0.4738, Time: 36.33s\n",
            "Epoch 3/10 - Loss: 1.8186, Test Acc: 0.4839, Time: 36.08s\n",
            "Epoch 4/10 - Loss: 1.7893, Test Acc: 0.4912, Time: 35.86s\n",
            "Epoch 5/10 - Loss: 1.7683, Test Acc: 0.4955, Time: 35.91s\n",
            "Epoch 6/10 - Loss: 1.7560, Test Acc: 0.4974, Time: 37.83s\n",
            "Epoch 7/10 - Loss: 1.7456, Test Acc: 0.4988, Time: 35.97s\n",
            "Epoch 8/10 - Loss: 1.7388, Test Acc: 0.4987, Time: 35.70s\n",
            "Epoch 9/10 - Loss: 1.7331, Test Acc: 0.5010, Time: 36.24s\n",
            "Epoch 10/10 - Loss: 1.7279, Test Acc: 0.5037, Time: 35.74s\n",
            "\n",
            "Transformer Model - Layers: 2, Heads: 2\n",
            "Model Size: 285505 parameters\n",
            "Epoch 1/10 - Loss: 1.9949, Test Acc: 0.4776, Time: 53.21s\n",
            "Epoch 2/10 - Loss: 1.7773, Test Acc: 0.4963, Time: 53.38s\n",
            "Epoch 3/10 - Loss: 1.7283, Test Acc: 0.5066, Time: 53.16s\n",
            "Epoch 4/10 - Loss: 1.7018, Test Acc: 0.5092, Time: 53.92s\n",
            "Epoch 5/10 - Loss: 1.6861, Test Acc: 0.5124, Time: 52.90s\n",
            "Epoch 6/10 - Loss: 1.6730, Test Acc: 0.5151, Time: 53.25s\n",
            "Epoch 7/10 - Loss: 1.6642, Test Acc: 0.5191, Time: 52.82s\n",
            "Epoch 8/10 - Loss: 1.6552, Test Acc: 0.5197, Time: 53.95s\n",
            "Epoch 9/10 - Loss: 1.6504, Test Acc: 0.5211, Time: 52.87s\n",
            "Epoch 10/10 - Loss: 1.6435, Test Acc: 0.5194, Time: 53.36s\n",
            "\n",
            "Transformer Model - Layers: 2, Heads: 4\n",
            "Model Size: 285505 parameters\n",
            "Epoch 1/10 - Loss: 1.9663, Test Acc: 0.4855, Time: 54.89s\n",
            "Epoch 2/10 - Loss: 1.7420, Test Acc: 0.5064, Time: 55.76s\n",
            "Epoch 3/10 - Loss: 1.6938, Test Acc: 0.5117, Time: 54.96s\n",
            "Epoch 4/10 - Loss: 1.6675, Test Acc: 0.5197, Time: 55.21s\n",
            "Epoch 5/10 - Loss: 1.6480, Test Acc: 0.5212, Time: 55.24s\n",
            "Epoch 6/10 - Loss: 1.6360, Test Acc: 0.5248, Time: 55.01s\n",
            "Epoch 7/10 - Loss: 1.6272, Test Acc: 0.5259, Time: 55.75s\n",
            "Epoch 8/10 - Loss: 1.6179, Test Acc: 0.5270, Time: 54.73s\n",
            "Epoch 9/10 - Loss: 1.6120, Test Acc: 0.5295, Time: 55.20s\n",
            "Epoch 10/10 - Loss: 1.6058, Test Acc: 0.5290, Time: 55.09s\n",
            "\n",
            "Transformer Model - Layers: 4, Heads: 2\n",
            "Model Size: 550465 parameters\n",
            "Epoch 1/10 - Loss: 1.9597, Test Acc: 0.4880, Time: 91.10s\n",
            "Epoch 2/10 - Loss: 1.7309, Test Acc: 0.5029, Time: 90.75s\n",
            "Epoch 3/10 - Loss: 1.6785, Test Acc: 0.5121, Time: 90.90s\n",
            "Epoch 4/10 - Loss: 1.6491, Test Acc: 0.5181, Time: 90.59s\n",
            "Epoch 5/10 - Loss: 1.6313, Test Acc: 0.5232, Time: 90.20s\n",
            "Epoch 6/10 - Loss: 1.6173, Test Acc: 0.5274, Time: 91.03s\n",
            "Epoch 7/10 - Loss: 1.6031, Test Acc: 0.5281, Time: 90.44s\n",
            "Epoch 8/10 - Loss: 1.5923, Test Acc: 0.5295, Time: 91.63s\n",
            "Epoch 9/10 - Loss: 1.5849, Test Acc: 0.5308, Time: 91.32s\n",
            "Epoch 10/10 - Loss: 1.5772, Test Acc: 0.5348, Time: 90.28s\n",
            "\n",
            "Transformer Model - Layers: 4, Heads: 4\n",
            "Model Size: 550465 parameters\n",
            "Epoch 1/10 - Loss: 1.9470, Test Acc: 0.4880, Time: 95.18s\n",
            "Epoch 2/10 - Loss: 1.7181, Test Acc: 0.5090, Time: 94.94s\n",
            "Epoch 3/10 - Loss: 1.6671, Test Acc: 0.5137, Time: 95.01s\n",
            "Epoch 4/10 - Loss: 1.6391, Test Acc: 0.5232, Time: 94.98s\n",
            "Epoch 5/10 - Loss: 1.6186, Test Acc: 0.5269, Time: 94.98s\n",
            "Epoch 6/10 - Loss: 1.6033, Test Acc: 0.5287, Time: 94.94s\n",
            "Epoch 7/10 - Loss: 1.5917, Test Acc: 0.5319, Time: 94.94s\n",
            "Epoch 8/10 - Loss: 1.5839, Test Acc: 0.5319, Time: 95.08s\n",
            "Epoch 9/10 - Loss: 1.5744, Test Acc: 0.5338, Time: 95.05s\n",
            "Epoch 10/10 - Loss: 1.5670, Test Acc: 0.5377, Time: 95.71s\n",
            "\n",
            "=== Transformer Experiments | Sequence Length: 50 ===\n",
            "\n",
            "Transformer Model - Layers: 1, Heads: 2\n",
            "Model Size: 155585 parameters\n",
            "Epoch 1/10 - Loss: 2.0827, Test Acc: 0.4548, Time: 43.98s\n",
            "Epoch 2/10 - Loss: 1.8926, Test Acc: 0.4708, Time: 43.80s\n",
            "Epoch 3/10 - Loss: 1.8546, Test Acc: 0.4759, Time: 43.37s\n",
            "Epoch 4/10 - Loss: 1.8358, Test Acc: 0.4768, Time: 43.63s\n",
            "Epoch 5/10 - Loss: 1.8233, Test Acc: 0.4819, Time: 43.77s\n",
            "Epoch 6/10 - Loss: 1.8160, Test Acc: 0.4832, Time: 43.33s\n",
            "Epoch 7/10 - Loss: 1.8110, Test Acc: 0.4849, Time: 43.68s\n",
            "Epoch 8/10 - Loss: 1.8041, Test Acc: 0.4872, Time: 44.10s\n",
            "Epoch 9/10 - Loss: 1.8014, Test Acc: 0.4872, Time: 43.38s\n",
            "Epoch 10/10 - Loss: 1.7977, Test Acc: 0.4887, Time: 43.60s\n",
            "\n",
            "Transformer Model - Layers: 1, Heads: 4\n",
            "Model Size: 155585 parameters\n",
            "Epoch 1/10 - Loss: 2.0478, Test Acc: 0.4695, Time: 44.82s\n",
            "Epoch 2/10 - Loss: 1.8238, Test Acc: 0.4883, Time: 44.43s\n",
            "Epoch 3/10 - Loss: 1.7789, Test Acc: 0.4948, Time: 44.60s\n",
            "Epoch 4/10 - Loss: 1.7565, Test Acc: 0.4978, Time: 44.74s\n",
            "Epoch 5/10 - Loss: 1.7417, Test Acc: 0.5004, Time: 44.61s\n",
            "Epoch 6/10 - Loss: 1.7318, Test Acc: 0.5055, Time: 44.56s\n",
            "Epoch 7/10 - Loss: 1.7239, Test Acc: 0.5057, Time: 44.56s\n",
            "Epoch 8/10 - Loss: 1.7183, Test Acc: 0.5061, Time: 44.74s\n",
            "Epoch 9/10 - Loss: 1.7127, Test Acc: 0.5082, Time: 44.42s\n",
            "Epoch 10/10 - Loss: 1.7077, Test Acc: 0.5086, Time: 44.59s\n",
            "\n",
            "Transformer Model - Layers: 2, Heads: 2\n",
            "Model Size: 288065 parameters\n",
            "Epoch 1/10 - Loss: 2.0186, Test Acc: 0.4742, Time: 73.31s\n",
            "Epoch 2/10 - Loss: 1.7848, Test Acc: 0.4953, Time: 73.31s\n",
            "Epoch 3/10 - Loss: 1.7312, Test Acc: 0.5058, Time: 73.47s\n",
            "Epoch 4/10 - Loss: 1.7021, Test Acc: 0.5093, Time: 73.55s\n",
            "Epoch 5/10 - Loss: 1.6828, Test Acc: 0.5135, Time: 73.38s\n",
            "Epoch 6/10 - Loss: 1.6664, Test Acc: 0.5174, Time: 73.45s\n",
            "Epoch 7/10 - Loss: 1.6551, Test Acc: 0.5215, Time: 73.31s\n",
            "Epoch 8/10 - Loss: 1.6468, Test Acc: 0.5220, Time: 73.27s\n",
            "Epoch 9/10 - Loss: 1.6394, Test Acc: 0.5232, Time: 73.25s\n",
            "Epoch 10/10 - Loss: 1.6323, Test Acc: 0.5246, Time: 73.32s\n",
            "\n",
            "Transformer Model - Layers: 2, Heads: 4\n",
            "Model Size: 288065 parameters\n",
            "Epoch 1/10 - Loss: 1.9795, Test Acc: 0.4884, Time: 76.34s\n",
            "Epoch 2/10 - Loss: 1.7363, Test Acc: 0.5065, Time: 75.88s\n",
            "Epoch 3/10 - Loss: 1.6834, Test Acc: 0.5144, Time: 76.10s\n",
            "Epoch 4/10 - Loss: 1.6535, Test Acc: 0.5203, Time: 76.11s\n",
            "Epoch 5/10 - Loss: 1.6342, Test Acc: 0.5235, Time: 75.91s\n",
            "Epoch 6/10 - Loss: 1.6193, Test Acc: 0.5296, Time: 76.16s\n",
            "Epoch 7/10 - Loss: 1.6077, Test Acc: 0.5307, Time: 76.08s\n",
            "Epoch 8/10 - Loss: 1.5986, Test Acc: 0.5338, Time: 75.95s\n",
            "Epoch 9/10 - Loss: 1.5905, Test Acc: 0.5322, Time: 76.20s\n",
            "Epoch 10/10 - Loss: 1.5835, Test Acc: 0.5356, Time: 76.07s\n",
            "\n",
            "Transformer Model - Layers: 4, Heads: 2\n",
            "Model Size: 553025 parameters\n",
            "Epoch 1/10 - Loss: 1.9833, Test Acc: 0.4882, Time: 134.96s\n",
            "Epoch 2/10 - Loss: 1.7350, Test Acc: 0.5077, Time: 134.91s\n",
            "Epoch 3/10 - Loss: 1.6822, Test Acc: 0.5131, Time: 134.81s\n",
            "Epoch 4/10 - Loss: 1.6527, Test Acc: 0.5184, Time: 134.70s\n",
            "Epoch 5/10 - Loss: 1.6322, Test Acc: 0.5240, Time: 134.67s\n",
            "Epoch 6/10 - Loss: 1.6161, Test Acc: 0.5257, Time: 134.70s\n",
            "Epoch 7/10 - Loss: 1.6048, Test Acc: 0.5294, Time: 134.64s\n",
            "Epoch 8/10 - Loss: 1.5940, Test Acc: 0.5305, Time: 134.58s\n",
            "Epoch 9/10 - Loss: 1.5853, Test Acc: 0.5329, Time: 134.64s\n",
            "Epoch 10/10 - Loss: 1.5776, Test Acc: 0.5336, Time: 134.68s\n",
            "\n",
            "Transformer Model - Layers: 4, Heads: 4\n",
            "Model Size: 553025 parameters\n",
            "Epoch 1/10 - Loss: 1.9564, Test Acc: 0.4888, Time: 140.24s\n",
            "Epoch 2/10 - Loss: 1.7084, Test Acc: 0.5102, Time: 140.49s\n",
            "Epoch 3/10 - Loss: 1.6585, Test Acc: 0.5193, Time: 140.31s\n",
            "Epoch 4/10 - Loss: 1.6291, Test Acc: 0.5248, Time: 140.13s\n",
            "Epoch 5/10 - Loss: 1.6095, Test Acc: 0.5289, Time: 140.08s\n",
            "Epoch 6/10 - Loss: 1.5939, Test Acc: 0.5318, Time: 140.11s\n",
            "Epoch 7/10 - Loss: 1.5810, Test Acc: 0.5341, Time: 140.05s\n",
            "Epoch 8/10 - Loss: 1.5701, Test Acc: 0.5363, Time: 140.24s\n",
            "Epoch 9/10 - Loss: 1.5615, Test Acc: 0.5386, Time: 140.01s\n",
            "Epoch 10/10 - Loss: 1.5541, Test Acc: 0.5391, Time: 140.05s\n",
            "\n",
            "=== RNN Experiment | Sequence Length: 20 ===\n",
            "RNN Model Size: 148801 parameters\n",
            "Epoch 1/10 - Loss: 1.8323, Test Acc: 0.5109, Time: 24.78s\n",
            "Epoch 2/10 - Loss: 1.5821, Test Acc: 0.5320, Time: 24.65s\n",
            "Epoch 3/10 - Loss: 1.5165, Test Acc: 0.5441, Time: 24.65s\n",
            "Epoch 4/10 - Loss: 1.4793, Test Acc: 0.5491, Time: 24.62s\n",
            "Epoch 5/10 - Loss: 1.4541, Test Acc: 0.5559, Time: 24.93s\n",
            "Epoch 6/10 - Loss: 1.4358, Test Acc: 0.5577, Time: 25.14s\n",
            "Epoch 7/10 - Loss: 1.4214, Test Acc: 0.5619, Time: 25.14s\n",
            "Epoch 8/10 - Loss: 1.4097, Test Acc: 0.5632, Time: 25.08s\n",
            "Epoch 9/10 - Loss: 1.4001, Test Acc: 0.5638, Time: 24.69s\n",
            "Epoch 10/10 - Loss: 1.3915, Test Acc: 0.5652, Time: 24.68s\n",
            "\n",
            "=== RNN Experiment | Sequence Length: 30 ===\n",
            "RNN Model Size: 148801 parameters\n",
            "Epoch 1/10 - Loss: 1.8335, Test Acc: 0.5119, Time: 27.73s\n",
            "Epoch 2/10 - Loss: 1.5762, Test Acc: 0.5368, Time: 28.13s\n",
            "Epoch 3/10 - Loss: 1.5088, Test Acc: 0.5478, Time: 27.60s\n",
            "Epoch 4/10 - Loss: 1.4709, Test Acc: 0.5532, Time: 27.69s\n",
            "Epoch 5/10 - Loss: 1.4458, Test Acc: 0.5581, Time: 28.14s\n",
            "Epoch 6/10 - Loss: 1.4269, Test Acc: 0.5606, Time: 27.72s\n",
            "Epoch 7/10 - Loss: 1.4133, Test Acc: 0.5645, Time: 27.60s\n",
            "Epoch 8/10 - Loss: 1.4019, Test Acc: 0.5650, Time: 28.08s\n",
            "Epoch 9/10 - Loss: 1.3920, Test Acc: 0.5655, Time: 27.65s\n",
            "Epoch 10/10 - Loss: 1.3840, Test Acc: 0.5665, Time: 27.66s\n",
            "\n",
            "=== Summary of Transformer Experiments (Sequence Length 20) ===\n",
            "Layers: 1, Heads: 2 -> Loss: 1.7938, Test Acc: 0.4818, Perplexity: 6.0122, Avg Epoch Time: 34.31s, Total Time: 343.07s, Model Size: 151745\n",
            "Layers: 1, Heads: 4 -> Loss: 1.7203, Test Acc: 0.5038, Perplexity: 5.5860, Avg Epoch Time: 34.26s, Total Time: 342.56s, Model Size: 151745\n",
            "Layers: 2, Heads: 2 -> Loss: 1.6508, Test Acc: 0.5194, Perplexity: 5.2111, Avg Epoch Time: 49.14s, Total Time: 491.39s, Model Size: 284225\n",
            "Layers: 2, Heads: 4 -> Loss: 1.6123, Test Acc: 0.5290, Perplexity: 5.0141, Avg Epoch Time: 49.25s, Total Time: 492.48s, Model Size: 284225\n",
            "Layers: 4, Heads: 2 -> Loss: 1.6018, Test Acc: 0.5260, Perplexity: 4.9620, Avg Epoch Time: 78.58s, Total Time: 785.77s, Model Size: 549185\n",
            "Layers: 4, Heads: 4 -> Loss: 1.5832, Test Acc: 0.5324, Perplexity: 4.8707, Avg Epoch Time: 81.02s, Total Time: 810.19s, Model Size: 549185\n",
            "\n",
            "=== Summary of Transformer Experiments (Sequence Length 30) ===\n",
            "Layers: 1, Heads: 2 -> Loss: 1.7988, Test Acc: 0.4834, Perplexity: 6.0426, Avg Epoch Time: 35.58s, Total Time: 355.85s, Model Size: 153025\n",
            "Layers: 1, Heads: 4 -> Loss: 1.7279, Test Acc: 0.5037, Perplexity: 5.6289, Avg Epoch Time: 36.16s, Total Time: 361.56s, Model Size: 153025\n",
            "Layers: 2, Heads: 2 -> Loss: 1.6435, Test Acc: 0.5194, Perplexity: 5.1731, Avg Epoch Time: 53.28s, Total Time: 532.82s, Model Size: 285505\n",
            "Layers: 2, Heads: 4 -> Loss: 1.6058, Test Acc: 0.5290, Perplexity: 4.9818, Avg Epoch Time: 55.18s, Total Time: 551.83s, Model Size: 285505\n",
            "Layers: 4, Heads: 2 -> Loss: 1.5772, Test Acc: 0.5348, Perplexity: 4.8415, Avg Epoch Time: 90.82s, Total Time: 908.25s, Model Size: 550465\n",
            "Layers: 4, Heads: 4 -> Loss: 1.5670, Test Acc: 0.5377, Perplexity: 4.7923, Avg Epoch Time: 95.08s, Total Time: 950.81s, Model Size: 550465\n",
            "\n",
            "=== Summary of Transformer Experiments (Sequence Length 50) ===\n",
            "Layers: 1, Heads: 2 -> Loss: 1.7977, Test Acc: 0.4887, Perplexity: 6.0360, Avg Epoch Time: 43.66s, Total Time: 436.62s, Model Size: 155585\n",
            "Layers: 1, Heads: 4 -> Loss: 1.7077, Test Acc: 0.5086, Perplexity: 5.5162, Avg Epoch Time: 44.61s, Total Time: 446.08s, Model Size: 155585\n",
            "Layers: 2, Heads: 2 -> Loss: 1.6323, Test Acc: 0.5246, Perplexity: 5.1156, Avg Epoch Time: 73.36s, Total Time: 733.62s, Model Size: 288065\n",
            "Layers: 2, Heads: 4 -> Loss: 1.5835, Test Acc: 0.5356, Perplexity: 4.8719, Avg Epoch Time: 76.08s, Total Time: 760.80s, Model Size: 288065\n",
            "Layers: 4, Heads: 2 -> Loss: 1.5776, Test Acc: 0.5336, Perplexity: 4.8431, Avg Epoch Time: 134.73s, Total Time: 1347.29s, Model Size: 553025\n",
            "Layers: 4, Heads: 4 -> Loss: 1.5541, Test Acc: 0.5391, Perplexity: 4.7308, Avg Epoch Time: 140.17s, Total Time: 1401.71s, Model Size: 553025\n",
            "\n",
            "=== Summary of RNN Experiments ===\n",
            "RNN (Sequence Length 20) -> Loss: 1.3915, Test Acc: 0.5652, Perplexity: 4.0209, Avg Epoch Time: 24.84s, Total Time: 248.36s, Model Size: 148801\n",
            "RNN (Sequence Length 30) -> Loss: 1.3840, Test Acc: 0.5665, Perplexity: 3.9909, Avg Epoch Time: 27.80s, Total Time: 278.00s, Model Size: 148801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from docx import Document\n",
        "doc_path = \"/content/drive/My Drive/Dataset - English to French.docx\"\n",
        "doc = Document(doc_path)\n",
        "raw_text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "namespace = {}\n",
        "exec(raw_text, namespace)\n",
        "english_to_french = namespace['english_to_french']\n",
        "import pandas as pd, re, math, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "def preprocess(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"[^a-zA-ZÀ-ÿ\\s]\", \"\", sentence)\n",
        "    tokens = sentence.split()\n",
        "    return tokens\n",
        "df = pd.DataFrame(english_to_french, columns=[\"English\", \"French\"])\n",
        "df[\"English_tokens\"] = df[\"English\"].apply(preprocess)\n",
        "df[\"French_tokens\"] = df[\"French\"].apply(preprocess)\n",
        "class Vocab:\n",
        "    def __init__(self, tokens_list, min_freq=1):\n",
        "        self.word2index = {\"<pad>\":0,\"<sos>\":1,\"<eos>\":2,\"<unk>\":3}\n",
        "        self.index2word = {0:\"<pad>\",1:\"<sos>\",2:\"<eos>\",3:\"<unk>\"}\n",
        "        self.word_freq = {}\n",
        "        self.min_freq = min_freq\n",
        "        self.build_vocab(tokens_list)\n",
        "    def build_vocab(self, tokens_list):\n",
        "        idx = len(self.word2index)\n",
        "        for tokens in tokens_list:\n",
        "            for word in tokens:\n",
        "                self.word_freq[word] = self.word_freq.get(word,0)+1\n",
        "        for word, freq in self.word_freq.items():\n",
        "            if freq>=self.min_freq:\n",
        "                self.word2index[word] = idx\n",
        "                self.index2word[idx] = word\n",
        "                idx+=1\n",
        "    def numericalize(self, tokens):\n",
        "        return [self.word2index.get(word, self.word2index[\"<unk>\"]) for word in tokens]\n",
        "english_vocab = Vocab(df[\"English_tokens\"])\n",
        "french_vocab = Vocab(df[\"French_tokens\"])\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, df, src_col, tgt_col, src_vocab, tgt_vocab):\n",
        "        self.df = df; self.src_col = src_col; self.tgt_col = tgt_col; self.src_vocab = src_vocab; self.tgt_vocab = tgt_vocab\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        src_tokens = self.df.iloc[idx][self.src_col]\n",
        "        tgt_tokens = self.df.iloc[idx][self.tgt_col]\n",
        "        src_indices = self.src_vocab.numericalize(src_tokens)\n",
        "        tgt_indices = [self.tgt_vocab.word2index[\"<sos>\"]] + self.tgt_vocab.numericalize(tgt_tokens) + [self.tgt_vocab.word2index[\"<eos>\"]]\n",
        "        return torch.tensor(src_indices), torch.tensor(tgt_indices)\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_lens = [len(s) for s in src_batch]\n",
        "    tgt_lens = [len(t) for t in tgt_batch]\n",
        "    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=english_vocab.word2index[\"<pad>\"])\n",
        "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=french_vocab.word2index[\"<pad>\"])\n",
        "    return src_padded, tgt_padded, src_lens, tgt_lens\n",
        "dataset_en2fr = TranslationDataset(df, \"English_tokens\", \"French_tokens\", english_vocab, french_vocab)\n",
        "dataloader_en2fr = DataLoader(dataset_en2fr, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "def compute_accuracy(output, tgt, pad_idx):\n",
        "    pred_tokens = output.argmax(dim=-1)\n",
        "    mask = (tgt != pad_idx)\n",
        "    correct = (pred_tokens == tgt)*mask\n",
        "    return correct.sum().item()/mask.sum().item()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, num_layers=1):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, num_layers, batch_first=True)\n",
        "    def forward(self, src, src_lens):\n",
        "        embedded = self.embedding(src)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, src_lens, batch_first=True, enforce_sorted=False)\n",
        "        outputs, hidden = self.gru(packed)\n",
        "        return hidden\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, num_layers=1):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, num_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        prediction = self.fc_out(output.squeeze(1))\n",
        "        return prediction, hidden\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq,self).__init__()\n",
        "        self.encoder = encoder; self.decoder = decoder; self.device = device\n",
        "    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0); tgt_len = tgt.size(1); tgt_vocab_size = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
        "        hidden = self.encoder(src, src_lens)\n",
        "        input_token = tgt[:,0]\n",
        "        for t in range(1,tgt_len):\n",
        "            output, hidden = self.decoder(input_token, hidden)\n",
        "            outputs[:,t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input_token = tgt[:,t] if teacher_force else top1\n",
        "        return outputs\n",
        "INPUT_DIM = len(english_vocab.word2index)\n",
        "OUTPUT_DIM = len(french_vocab.word2index)\n",
        "EMB_DIM = 256; HID_DIM = 512; N_LAYERS = 1; NUM_EPOCHS = 10\n",
        "encoder_p1 = Encoder(INPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS).to(device)\n",
        "decoder_p1 = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS).to(device)\n",
        "model_p1 = Seq2Seq(encoder_p1, decoder_p1, device).to(device)\n",
        "optimizer_p1 = optim.Adam(model_p1.parameters())\n",
        "criterion_p1 = nn.CrossEntropyLoss(ignore_index=french_vocab.word2index[\"<pad>\"])\n",
        "def train_model(model, dataloader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_lens, tgt)\n",
        "        output_dim = output.shape[-1]\n",
        "        output_for_loss = output[:,1:].reshape(-1, output_dim)\n",
        "        tgt_for_loss = tgt[:,1:].reshape(-1)\n",
        "        loss = criterion(output_for_loss, tgt_for_loss)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        acc = compute_accuracy(output[:,1:], tgt[:,1:], french_vocab.word2index[\"<pad>\"])\n",
        "        epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, src_lens, tgt, teacher_forcing_ratio=0)\n",
        "            output_dim = output.shape[-1]\n",
        "            output_for_loss = output[:,1:].reshape(-1, output_dim)\n",
        "            tgt_for_loss = tgt[:,1:].reshape(-1)\n",
        "            loss = criterion(output_for_loss, tgt_for_loss)\n",
        "            acc = compute_accuracy(output[:,1:], tgt[:,1:], french_vocab.word2index[\"<pad>\"])\n",
        "            epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "print(\"=== RNN Seq2Seq without Attention ===\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_acc = train_model(model_p1, dataloader_en2fr, optimizer_p1, criterion_p1)\n",
        "    val_loss, val_acc = evaluate_model(model_p1, dataloader_en2fr, criterion_p1)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
        "def translate_sentence(model, sentence, src_vocab, tgt_vocab, max_len=20):\n",
        "    model.eval()\n",
        "    tokens = preprocess(sentence)\n",
        "    indices = src_vocab.numericalize(tokens)\n",
        "    src_tensor = torch.tensor(indices).unsqueeze(0).to(device)\n",
        "    src_len = [len(indices)]\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(src_tensor, src_len)\n",
        "    input_token = tgt_vocab.word2index[\"<sos>\"]\n",
        "    translated_sentence = []\n",
        "    for _ in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(torch.tensor([input_token]).to(device), hidden)\n",
        "        top1 = output.argmax(1).item()\n",
        "        if top1 == tgt_vocab.word2index[\"<eos>\"]:\n",
        "            break\n",
        "        translated_sentence.append(tgt_vocab.index2word[top1])\n",
        "        input_token = top1\n",
        "    return \" \".join(translated_sentence)\n",
        "test_sentences = [\"She wears a red dress and dances at the party\",\n",
        "\"After they visit the museum, they play video games\",\n",
        "\"Although he is tired, he works hard every day\",\n",
        "\"She sings a song while cooking dinner\",\n",
        "\"We eat breakfast together before we go to the gym\",\n",
        "\"He said that the coffee is hot\",\n",
        "\"She thinks that the teacher explains the lesson well\",\n",
        "\"They do not enjoy the sunset when it rains\",\n",
        "\"She is not happy because the cat is sleeping on her dress\",\n",
        "\"He plays the guitar and also sings in the choir\"]\n",
        "print(\"=== RNN Seq2Seq without Attention Translation Test ===\")\n",
        "for sentence in test_sentences:\n",
        "    print(f\"\\nInput: {sentence}\")\n",
        "    output = translate_sentence(model_p1, sentence, english_vocab, french_vocab)\n",
        "    print(f\"Output: {output}\")\n",
        "class EncoderAttn(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, num_layers=1):\n",
        "        super(EncoderAttn,self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hid_dim*2, hid_dim)\n",
        "    def forward(self, src, src_lens, return_all=False):\n",
        "        embedded = self.embedding(src)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, src_lens, batch_first=True, enforce_sorted=False)\n",
        "        outputs, hidden = self.gru(packed)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        hidden = self.fc(hidden).unsqueeze(0)\n",
        "        if return_all:\n",
        "            return outputs, hidden\n",
        "        return hidden\n",
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, num_layers=1):\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.query_linear = nn.Linear(emb_dim, hid_dim)\n",
        "        self.attn_linear = nn.Linear(hid_dim*2, hid_dim)\n",
        "        self.gru = nn.GRU(emb_dim+hid_dim, hid_dim, num_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(emb_dim+hid_dim*2, output_dim)\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).unsqueeze(1)\n",
        "        query = self.query_linear(embedded)\n",
        "        proj_enc = self.attn_linear(encoder_outputs)\n",
        "        attn_weights = torch.bmm(query, proj_enc.transpose(1,2))\n",
        "        attn_weights = torch.softmax(attn_weights, dim=-1)\n",
        "        context = torch.bmm(attn_weights, proj_enc)\n",
        "        rnn_input = torch.cat((embedded, context), dim=2)\n",
        "        output, hidden = self.gru(rnn_input, hidden)\n",
        "        output = output.squeeze(1)\n",
        "        context = context.squeeze(1)\n",
        "        embedded = embedded.squeeze(1)\n",
        "        prediction = self.fc_out(torch.cat((output, context, embedded), dim=1))\n",
        "        return prediction, hidden\n",
        "class Seq2SeqAttn(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2SeqAttn,self).__init__()\n",
        "        self.encoder = encoder; self.decoder = decoder; self.device = device\n",
        "    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0); tgt_len = tgt.size(1); tgt_vocab_size = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden = self.encoder(src, src_lens, return_all=True)\n",
        "        input_token = tgt[:,0]\n",
        "        for t in range(1,tgt_len):\n",
        "            output, hidden = self.decoder(input_token, hidden, encoder_outputs)\n",
        "            outputs[:,t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input_token = tgt[:,t] if teacher_force else top1\n",
        "        return outputs\n",
        "encoder_attn = EncoderAttn(INPUT_DIM, EMB_DIM, HID_DIM, 1).to(device)\n",
        "decoder_attn = AttnDecoder(OUTPUT_DIM, EMB_DIM, HID_DIM, 1).to(device)\n",
        "model_attn = Seq2SeqAttn(encoder_attn, decoder_attn, device).to(device)\n",
        "optimizer_attn = optim.Adam(model_attn.parameters())\n",
        "criterion_attn = nn.CrossEntropyLoss(ignore_index=french_vocab.word2index[\"<pad>\"])\n",
        "def train_model_attn(model, dataloader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_lens, tgt)\n",
        "        output_dim = output.shape[-1]\n",
        "        output_for_loss = output[:,1:].reshape(-1, output_dim)\n",
        "        tgt_for_loss = tgt[:,1:].reshape(-1)\n",
        "        loss = criterion(output_for_loss, tgt_for_loss)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        acc = compute_accuracy(output[:,1:], tgt[:,1:], french_vocab.word2index[\"<pad>\"])\n",
        "        epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "def evaluate_model_attn(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, src_lens, tgt, teacher_forcing_ratio=0)\n",
        "            output_dim = output.shape[-1]\n",
        "            output_for_loss = output[:,1:].reshape(-1, output_dim)\n",
        "            tgt_for_loss = tgt[:,1:].reshape(-1)\n",
        "            loss = criterion(output_for_loss, tgt_for_loss)\n",
        "            acc = compute_accuracy(output[:,1:], tgt[:,1:], french_vocab.word2index[\"<pad>\"])\n",
        "            epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "print(\"=== RNN Seq2Seq with Attention ===\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_acc = train_model_attn(model_attn, dataloader_en2fr, optimizer_attn, criterion_attn)\n",
        "    val_loss, val_acc = evaluate_model_attn(model_attn, dataloader_en2fr, criterion_attn)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
        "def translate_sentence_attn(model, sentence, src_vocab, tgt_vocab, max_len=20):\n",
        "    model.eval()\n",
        "    tokens = preprocess(sentence)\n",
        "    indices = src_vocab.numericalize(tokens)\n",
        "    src_tensor = torch.tensor(indices).unsqueeze(0).to(device)\n",
        "    src_len = [len(indices)]\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor, src_len, return_all=True)\n",
        "    input_token = torch.tensor([tgt_vocab.word2index[\"<sos>\"]]).to(device)\n",
        "    translated_sentence = []\n",
        "    for _ in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(input_token, hidden, encoder_outputs)\n",
        "        top1 = output.argmax(1)\n",
        "        if top1.item()==tgt_vocab.word2index[\"<eos>\"]:\n",
        "            break\n",
        "        translated_sentence.append(tgt_vocab.index2word[top1.item()])\n",
        "        input_token = top1\n",
        "    return \" \".join(translated_sentence)\n",
        "print(\"=== RNN Seq2Seq with Attention Translation Test ===\")\n",
        "for sentence in test_sentences:\n",
        "    print(f\"\\nInput: {sentence}\")\n",
        "    output = translate_sentence_attn(model_attn, sentence, english_vocab, french_vocab)\n",
        "    print(f\"Output: {output}\")\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding,self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float()*(-math.log(10000.0)/d_model))\n",
        "        pe[:,0::2] = torch.sin(position*div_term)\n",
        "        pe[:,1::2] = torch.cos(position*div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:,:x.size(1)]\n",
        "        return self.dropout(x)\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout=0.1):\n",
        "        super(TransformerModel,self).__init__()\n",
        "        self.src_embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "        self.d_model = d_model\n",
        "    def forward(self, src, tgt):\n",
        "        src_emb = self.pos_encoder(self.src_embedding(src)*math.sqrt(self.d_model))\n",
        "        tgt_emb = self.pos_encoder(self.tgt_embedding(tgt)*math.sqrt(self.d_model))\n",
        "        src_emb = src_emb.transpose(0,1)\n",
        "        tgt_emb = tgt_emb.transpose(0,1)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt_emb.size(0)).to(src.device)\n",
        "        output = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask)\n",
        "        output = self.fc_out(output.transpose(0,1))\n",
        "        return output\n",
        "def train_transformer(model, dataloader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        tgt_input = tgt[:,:-1]\n",
        "        output = model(src, tgt_input)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output.reshape(-1, output_dim)\n",
        "        tgt_out = tgt[:,1:].reshape(-1)\n",
        "        loss = criterion(output, tgt_out)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        acc = compute_accuracy(output.view(tgt.size(0), -1, output_dim), tgt[:,1:], french_vocab.word2index[\"<pad>\"])\n",
        "        epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "def evaluate_transformer(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:,:-1]\n",
        "            output = model(src, tgt_input)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.reshape(-1, output_dim)\n",
        "            tgt_out = tgt[:,1:].reshape(-1)\n",
        "            loss = criterion(output, tgt_out)\n",
        "            acc = compute_accuracy(output.view(tgt.size(0), -1, output_dim), tgt[:,1:], french_vocab.word2index[\"<pad>\"])\n",
        "            epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "def translate_sentence_transformer(model, sentence, src_vocab, tgt_vocab, max_len=20):\n",
        "    model.eval()\n",
        "    tokens = preprocess(sentence)\n",
        "    indices = src_vocab.numericalize(tokens)\n",
        "    src_tensor = torch.tensor(indices).unsqueeze(0).to(device)\n",
        "    src_emb = model.pos_encoder(model.src_embedding(src_tensor)*math.sqrt(model.d_model)).transpose(0,1)\n",
        "    memory = model.transformer.encoder(src_emb)\n",
        "    tgt_indices = [tgt_vocab.word2index[\"<sos>\"]]\n",
        "    for i in range(max_len):\n",
        "        tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
        "        tgt_emb = model.pos_encoder(model.tgt_embedding(tgt_tensor)*math.sqrt(model.d_model)).transpose(0,1)\n",
        "        tgt_mask = model.transformer.generate_square_subsequent_mask(tgt_emb.size(0)).to(device)\n",
        "        output = model.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n",
        "        output = model.fc_out(output.transpose(0,1))\n",
        "        next_token = output[0,-1].argmax().item()\n",
        "        if next_token==tgt_vocab.word2index[\"<eos>\"]:\n",
        "            break\n",
        "        tgt_indices.append(next_token)\n",
        "    return \" \".join([tgt_vocab.index2word[idx] for idx in tgt_indices[1:]])\n",
        "best_trans_acc = -1\n",
        "best_trans_model = None\n",
        "trans_results = {}\n",
        "print(\"=== Transformer Seq2Seq Experiments ===\")\n",
        "for num_layers in [1,2,4]:\n",
        "    for nhead in [2,4]:\n",
        "        model_trans = TransformerModel(INPUT_DIM, OUTPUT_DIM, EMB_DIM, nhead, num_layers, num_layers, HID_DIM).to(device)\n",
        "        optimizer_trans = optim.Adam(model_trans.parameters())\n",
        "        criterion_trans = nn.CrossEntropyLoss(ignore_index=french_vocab.word2index[\"<pad>\"])\n",
        "        for epoch in range(NUM_EPOCHS):\n",
        "            train_loss, train_acc = train_transformer(model_trans, dataloader_en2fr, optimizer_trans, criterion_trans)\n",
        "            val_loss, val_acc = evaluate_transformer(model_trans, dataloader_en2fr, criterion_trans)\n",
        "        trans_results[f\"layers{num_layers}_heads{nhead}\"] = (val_loss, val_acc)\n",
        "        if val_acc > best_trans_acc:\n",
        "            best_trans_acc = val_acc\n",
        "            best_trans_model = model_trans\n",
        "        print(f\"Config layers={num_layers}, heads={nhead}: Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
        "print(\"=== Transformer Translation Test ===\")\n",
        "for sentence in test_sentences:\n",
        "    print(f\"\\nInput: {sentence}\")\n",
        "    output = translate_sentence_transformer(best_trans_model, sentence, english_vocab, french_vocab)\n",
        "    print(f\"Output: {output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWPOi7wlHzw4",
        "outputId": "6174c2bf-9a44-41ff-aa57-5f17c19a62cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "=== RNN Seq2Seq without Attention ===\n",
            "Epoch 1: Train Loss = 4.7463, Train Acc = 0.2239, Val Loss = 3.8285, Val Acc = 0.3225\n",
            "Epoch 2: Train Loss = 3.5566, Train Acc = 0.3675, Val Loss = 3.1059, Val Acc = 0.3967\n",
            "Epoch 3: Train Loss = 2.9498, Train Acc = 0.4168, Val Loss = 2.4265, Val Acc = 0.4944\n",
            "Epoch 4: Train Loss = 2.2823, Train Acc = 0.4844, Val Loss = 1.6858, Val Acc = 0.6723\n",
            "Epoch 5: Train Loss = 1.5539, Train Acc = 0.6613, Val Loss = 0.9628, Val Acc = 0.8365\n",
            "Epoch 6: Train Loss = 0.9748, Train Acc = 0.8117, Val Loss = 0.4993, Val Acc = 0.9447\n",
            "Epoch 7: Train Loss = 0.5056, Train Acc = 0.9135, Val Loss = 0.2317, Val Acc = 0.9739\n",
            "Epoch 8: Train Loss = 0.2431, Train Acc = 0.9624, Val Loss = 0.0965, Val Acc = 0.9987\n",
            "Epoch 9: Train Loss = 0.0944, Train Acc = 0.9931, Val Loss = 0.0416, Val Acc = 0.9984\n",
            "Epoch 10: Train Loss = 0.0458, Train Acc = 0.9974, Val Loss = 0.0240, Val Acc = 1.0000\n",
            "=== RNN Seq2Seq without Attention Translation Test ===\n",
            "\n",
            "Input: She wears a red dress and dances at the party\n",
            "Output: elle danse à la fête\n",
            "\n",
            "Input: After they visit the museum, they play video games\n",
            "Output: ils jouent aux jeux vidéo\n",
            "\n",
            "Input: Although he is tired, he works hard every day\n",
            "Output: il travaille dur tous les jours\n",
            "\n",
            "Input: She sings a song while cooking dinner\n",
            "Output: elle étudie les mathématiques à luniversité\n",
            "\n",
            "Input: We eat breakfast together before we go to the gym\n",
            "Output: nous plantons des fleurs dans le jardin\n",
            "\n",
            "Input: He said that the coffee is hot\n",
            "Output: le café est chaud\n",
            "\n",
            "Input: She thinks that the teacher explains the lesson well\n",
            "Output: le soleil se couche le soir\n",
            "\n",
            "Input: They do not enjoy the sunset when it rains\n",
            "Output: ils font de la randonnée dans la forêt\n",
            "\n",
            "Input: She is not happy because the cat is sleeping on her dress\n",
            "Output: elle porte une robe rouge\n",
            "\n",
            "Input: He plays the guitar and also sings in the choir\n",
            "Output: il chante dans le chur\n",
            "=== RNN Seq2Seq with Attention ===\n",
            "Epoch 1: Train Loss = 4.6871, Train Acc = 0.2428, Val Loss = 3.5955, Val Acc = 0.3253\n",
            "Epoch 2: Train Loss = 3.3981, Train Acc = 0.3822, Val Loss = 2.7624, Val Acc = 0.4419\n",
            "Epoch 3: Train Loss = 2.5004, Train Acc = 0.4623, Val Loss = 1.7912, Val Acc = 0.5992\n",
            "Epoch 4: Train Loss = 1.7165, Train Acc = 0.6079, Val Loss = 1.1267, Val Acc = 0.7459\n",
            "Epoch 5: Train Loss = 1.0942, Train Acc = 0.7401, Val Loss = 0.8883, Val Acc = 0.7960\n",
            "Epoch 6: Train Loss = 0.8436, Train Acc = 0.7965, Val Loss = 0.7937, Val Acc = 0.8110\n",
            "Epoch 7: Train Loss = 0.5898, Train Acc = 0.8604, Val Loss = 0.6115, Val Acc = 0.8680\n",
            "Epoch 8: Train Loss = 0.5105, Train Acc = 0.8784, Val Loss = 0.5141, Val Acc = 0.8727\n",
            "Epoch 9: Train Loss = 0.3311, Train Acc = 0.9145, Val Loss = 0.3471, Val Acc = 0.9067\n",
            "Epoch 10: Train Loss = 0.3384, Train Acc = 0.9089, Val Loss = 0.3476, Val Acc = 0.9360\n",
            "=== RNN Seq2Seq with Attention Translation Test ===\n",
            "\n",
            "Input: She wears a red dress and dances at the party\n",
            "Output: elle danse à la leçon\n",
            "\n",
            "Input: After they visit the museum, they play video games\n",
            "Output: ils jouent aux jeux vidéo\n",
            "\n",
            "Input: Although he is tired, he works hard every day\n",
            "Output: il travaille dur tous les jours\n",
            "\n",
            "Input: She sings a song while cooking dinner\n",
            "Output: elle chante une chanson\n",
            "\n",
            "Input: We eat breakfast together before we go to the gym\n",
            "Output: nous pratiquons le petit déjeuner ensemble\n",
            "\n",
            "Input: He said that the coffee is hot\n",
            "Output: il a faim\n",
            "\n",
            "Input: She thinks that the teacher explains the lesson well\n",
            "Output: elle arrose dans le\n",
            "\n",
            "Input: They do not enjoy the sunset when it rains\n",
            "Output: ils apprécient le coucher du soleil\n",
            "\n",
            "Input: She is not happy because the cat is sleeping on her dress\n",
            "Output: elle est dans le\n",
            "\n",
            "Input: He plays the guitar and also sings in the choir\n",
            "Output: il attend dans le matin\n",
            "=== Transformer Seq2Seq Experiments ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config layers=1, heads=2: Val Loss = 0.6196, Val Acc = 0.8843\n",
            "Config layers=1, heads=4: Val Loss = 0.3687, Val Acc = 0.9328\n",
            "Config layers=2, heads=2: Val Loss = 1.8247, Val Acc = 0.5534\n",
            "Config layers=2, heads=4: Val Loss = 1.6366, Val Acc = 0.5741\n",
            "Config layers=4, heads=2: Val Loss = 4.5403, Val Acc = 0.1771\n",
            "Config layers=4, heads=4: Val Loss = 4.5466, Val Acc = 0.1754\n",
            "=== Transformer Translation Test ===\n",
            "\n",
            "Input: She wears a red dress and dances at the party\n",
            "Output: elle danse à la porte une robe rouge\n",
            "\n",
            "Input: After they visit the museum, they play video games\n",
            "Output: ils jouent aux jeux vidéo\n",
            "\n",
            "Input: Although he is tired, he works hard every day\n",
            "Output: il travaille dur tous les jours\n",
            "\n",
            "Input: She sings a song while cooking dinner\n",
            "Output: elle danse avec grâce\n",
            "\n",
            "Input: We eat breakfast together before we go to the gym\n",
            "Output: nous prenons le dîner ensemble\n",
            "\n",
            "Input: He said that the coffee is hot\n",
            "Output: il a faim dans la leçon\n",
            "\n",
            "Input: She thinks that the teacher explains the lesson well\n",
            "Output: elle danse avec\n",
            "\n",
            "Input: They do not enjoy the sunset when it rains\n",
            "Output: ils apprécient le coucher du soleil\n",
            "\n",
            "Input: She is not happy because the cat is sleeping on her dress\n",
            "Output: elle danse avec grâce\n",
            "\n",
            "Input: He plays the guitar and also sings in the choir\n",
            "Output: il chante dans le chur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from docx import Document\n",
        "doc_path = \"/content/drive/My Drive/Dataset - English to French.docx\"\n",
        "doc = Document(doc_path)\n",
        "raw_text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "namespace = {}\n",
        "exec(raw_text, namespace)\n",
        "english_to_french = namespace['english_to_french']\n",
        "import pandas as pd, re, math, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "def preprocess(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"[^a-zA-ZÀ-ÿ\\s]\", \"\", sentence)\n",
        "    tokens = sentence.split()\n",
        "    return tokens\n",
        "df = pd.DataFrame(english_to_french, columns=[\"English\", \"French\"])\n",
        "df[\"English_tokens\"] = df[\"English\"].apply(preprocess)\n",
        "df[\"French_tokens\"] = df[\"French\"].apply(preprocess)\n",
        "class Vocab:\n",
        "    def __init__(self, tokens_list, min_freq=1):\n",
        "        self.word2index = {\"<pad>\":0,\"<sos>\":1,\"<eos>\":2,\"<unk>\":3}\n",
        "        self.index2word = {0:\"<pad>\",1:\"<sos>\",2:\"<eos>\",3:\"<unk>\"}\n",
        "        self.word_freq = {}\n",
        "        self.min_freq = min_freq\n",
        "        self.build_vocab(tokens_list)\n",
        "    def build_vocab(self, tokens_list):\n",
        "        idx = len(self.word2index)\n",
        "        for tokens in tokens_list:\n",
        "            for word in tokens:\n",
        "                self.word_freq[word] = self.word_freq.get(word,0)+1\n",
        "        for word, freq in self.word_freq.items():\n",
        "            if freq>=self.min_freq:\n",
        "                self.word2index[word] = idx\n",
        "                self.index2word[idx] = word\n",
        "                idx+=1\n",
        "    def numericalize(self, tokens):\n",
        "        return [self.word2index.get(word, self.word2index[\"<unk>\"]) for word in tokens]\n",
        "english_vocab = Vocab(df[\"English_tokens\"])\n",
        "french_vocab = Vocab(df[\"French_tokens\"])\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, df, src_col, tgt_col, src_vocab, tgt_vocab):\n",
        "        self.df = df; self.src_col = src_col; self.tgt_col = tgt_col; self.src_vocab = src_vocab; self.tgt_vocab = tgt_vocab\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        src_tokens = self.df.iloc[idx][self.src_col]\n",
        "        tgt_tokens = self.df.iloc[idx][self.tgt_col]\n",
        "        src_indices = self.src_vocab.numericalize(src_tokens)\n",
        "        tgt_indices = [self.tgt_vocab.word2index[\"<sos>\"]] + self.tgt_vocab.numericalize(tgt_tokens) + [self.tgt_vocab.word2index[\"<eos>\"]]\n",
        "        return torch.tensor(src_indices), torch.tensor(tgt_indices)\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_lens = [len(s) for s in src_batch]\n",
        "    tgt_lens = [len(t) for t in tgt_batch]\n",
        "    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=french_vocab.word2index[\"<pad>\"])\n",
        "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=english_vocab.word2index[\"<pad>\"])\n",
        "    return src_padded, tgt_padded, src_lens, tgt_lens\n",
        "dataset_f2e = TranslationDataset(df, \"French_tokens\", \"English_tokens\", french_vocab, english_vocab)\n",
        "dataloader_f2e = DataLoader(dataset_f2e, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "def compute_accuracy(output, tgt, pad_idx):\n",
        "    pred_tokens = output.argmax(dim=-1)\n",
        "    mask = (tgt != pad_idx)\n",
        "    correct = (pred_tokens == tgt)*mask\n",
        "    return correct.sum().item()/mask.sum().item()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, num_layers=1):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, num_layers, batch_first=True)\n",
        "    def forward(self, src, src_lens):\n",
        "        embedded = self.embedding(src)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, src_lens, batch_first=True, enforce_sorted=False)\n",
        "        outputs, hidden = self.gru(packed)\n",
        "        return hidden\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, num_layers=1):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, num_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        prediction = self.fc_out(output.squeeze(1))\n",
        "        return prediction, hidden\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq,self).__init__()\n",
        "        self.encoder = encoder; self.decoder = decoder; self.device = device\n",
        "    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0); tgt_len = tgt.size(1); tgt_vocab_size = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
        "        hidden = self.encoder(src, src_lens)\n",
        "        input_token = tgt[:,0]\n",
        "        for t in range(1,tgt_len):\n",
        "            output, hidden = self.decoder(input_token, hidden)\n",
        "            outputs[:,t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input_token = tgt[:,t] if teacher_force else top1\n",
        "        return outputs\n",
        "EMB_DIM = 256; HID_DIM = 512; N_LAYERS = 1; NUM_EPOCHS = 10\n",
        "encoder_f2e = Encoder(len(french_vocab.word2index), EMB_DIM, HID_DIM, N_LAYERS).to(device)\n",
        "decoder_f2e = Decoder(len(english_vocab.word2index), EMB_DIM, HID_DIM, N_LAYERS).to(device)\n",
        "model_f2e = Seq2Seq(encoder_f2e, decoder_f2e, device).to(device)\n",
        "optimizer_f2e = optim.Adam(model_f2e.parameters())\n",
        "criterion_f2e = nn.CrossEntropyLoss(ignore_index=english_vocab.word2index[\"<pad>\"])\n",
        "def train_model(model, dataloader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_lens, tgt)\n",
        "        output_dim = output.shape[-1]\n",
        "        output_for_loss = output[:,1:].reshape(-1, output_dim)\n",
        "        tgt_for_loss = tgt[:,1:].reshape(-1)\n",
        "        loss = criterion(output_for_loss, tgt_for_loss)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        acc = compute_accuracy(output[:,1:], tgt[:,1:], english_vocab.word2index[\"<pad>\"])\n",
        "        epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, src_lens, tgt, teacher_forcing_ratio=0)\n",
        "            output_dim = output.shape[-1]\n",
        "            output_for_loss = output[:,1:].reshape(-1, output_dim)\n",
        "            tgt_for_loss = tgt[:,1:].reshape(-1)\n",
        "            loss = criterion(output_for_loss, tgt_for_loss)\n",
        "            acc = compute_accuracy(output[:,1:], tgt[:,1:], english_vocab.word2index[\"<pad>\"])\n",
        "            epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "print(\"=== RNN Seq2Seq French-to-English ===\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_acc = train_model(model_f2e, dataloader_f2e, optimizer_f2e, criterion_f2e)\n",
        "    val_loss, val_acc = evaluate_model(model_f2e, dataloader_f2e, criterion_f2e)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
        "def translate_sentence_f2e(model, sentence, src_vocab, tgt_vocab, max_len=20):\n",
        "    model.eval()\n",
        "    tokens = preprocess(sentence)\n",
        "    indices = src_vocab.numericalize(tokens)\n",
        "    src_tensor = torch.tensor(indices).unsqueeze(0).to(device)\n",
        "    src_len = [len(indices)]\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(src_tensor, src_len)\n",
        "    input_token = tgt_vocab.word2index[\"<sos>\"]\n",
        "    translated_sentence = []\n",
        "    for _ in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(torch.tensor([input_token]).to(device), hidden)\n",
        "        top1 = output.argmax(1).item()\n",
        "        if top1 == tgt_vocab.word2index[\"<eos>\"]:\n",
        "            break\n",
        "        translated_sentence.append(tgt_vocab.index2word[top1])\n",
        "        input_token = top1\n",
        "    return \" \".join(translated_sentence)\n",
        "test_french_sentences = [\"elle porte une robe rouge et danse à la fête\",\n",
        "\"après avoir visité le musée, ils jouent aux jeux vidéo\",\n",
        "\"bien qu'il soit fatigué, il travaille dur tous les jours\",\n",
        "\"elle chante une chanson en cuisinant le dîner\",\n",
        "\"nous prenons le petit déjeuner ensemble avant d'aller à la salle de sport\"]\n",
        "print(\"=== RNN Seq2Seq French-to-English Translation Test ===\")\n",
        "for sentence in test_french_sentences:\n",
        "    print(f\"\\nInput: {sentence}\")\n",
        "    output = translate_sentence_f2e(model_f2e, sentence, french_vocab, english_vocab)\n",
        "    print(f\"Output: {output}\")\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding,self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float()*(-math.log(10000.0)/d_model))\n",
        "        pe[:,0::2] = torch.sin(position*div_term)\n",
        "        pe[:,1::2] = torch.cos(position*div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:,:x.size(1)]\n",
        "        return self.dropout(x)\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout=0.1):\n",
        "        super(TransformerModel,self).__init__()\n",
        "        self.src_embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "        self.d_model = d_model\n",
        "    def forward(self, src, tgt):\n",
        "        src_emb = self.pos_encoder(self.src_embedding(src)*math.sqrt(self.d_model))\n",
        "        tgt_emb = self.pos_encoder(self.tgt_embedding(tgt)*math.sqrt(self.d_model))\n",
        "        src_emb = src_emb.transpose(0,1)\n",
        "        tgt_emb = tgt_emb.transpose(0,1)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt_emb.size(0)).to(src.device)\n",
        "        output = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask)\n",
        "        output = self.fc_out(output.transpose(0,1))\n",
        "        return output\n",
        "def train_transformer(model, dataloader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        tgt_input = tgt[:,:-1]\n",
        "        output = model(src, tgt_input)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output.reshape(-1, output_dim)\n",
        "        tgt_out = tgt[:,1:].reshape(-1)\n",
        "        loss = criterion(output, tgt_out)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        acc = compute_accuracy(output.view(tgt.size(0), -1, output_dim), tgt[:,1:], english_vocab.word2index[\"<pad>\"])\n",
        "        epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "def evaluate_transformer(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss=0; epoch_acc=0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt, src_lens, tgt_lens in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:,:-1]\n",
        "            output = model(src, tgt_input)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.reshape(-1, output_dim)\n",
        "            tgt_out = tgt[:,1:].reshape(-1)\n",
        "            loss = criterion(output, tgt_out)\n",
        "            acc = compute_accuracy(output.view(tgt.size(0), -1, output_dim), tgt[:,1:], english_vocab.word2index[\"<pad>\"])\n",
        "            epoch_loss += loss.item(); epoch_acc += acc\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "def translate_sentence_transformer(model, sentence, src_vocab, tgt_vocab, max_len=20):\n",
        "    model.eval()\n",
        "    tokens = preprocess(sentence)\n",
        "    indices = src_vocab.numericalize(tokens)\n",
        "    src_tensor = torch.tensor(indices).unsqueeze(0).to(device)\n",
        "    src_emb = model.pos_encoder(model.src_embedding(src_tensor)*math.sqrt(model.d_model)).transpose(0,1)\n",
        "    memory = model.transformer.encoder(src_emb)\n",
        "    tgt_indices = [tgt_vocab.word2index[\"<sos>\"]]\n",
        "    for i in range(max_len):\n",
        "        tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
        "        tgt_emb = model.pos_encoder(model.tgt_embedding(tgt_tensor)*math.sqrt(model.d_model)).transpose(0,1)\n",
        "        tgt_mask = model.transformer.generate_square_subsequent_mask(tgt_emb.size(0)).to(device)\n",
        "        output = model.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n",
        "        output = model.fc_out(output.transpose(0,1))\n",
        "        next_token = output[0,-1].argmax().item()\n",
        "        if next_token==tgt_vocab.word2index[\"<eos>\"]:\n",
        "            break\n",
        "        tgt_indices.append(next_token)\n",
        "    return \" \".join([tgt_vocab.index2word[idx] for idx in tgt_indices[1:]])\n",
        "best_trans_acc = -1\n",
        "best_trans_model = None\n",
        "trans_results = {}\n",
        "print(\"=== Transformer Seq2Seq French-to-English Experiments ===\")\n",
        "for num_layers in [1,2,4]:\n",
        "    for nhead in [2,4]:\n",
        "        model_trans = TransformerModel(len(french_vocab.word2index), len(english_vocab.word2index), EMB_DIM, nhead, num_layers, num_layers, HID_DIM).to(device)\n",
        "        optimizer_trans = optim.Adam(model_trans.parameters())\n",
        "        criterion_trans = nn.CrossEntropyLoss(ignore_index=english_vocab.word2index[\"<pad>\"])\n",
        "        for epoch in range(NUM_EPOCHS):\n",
        "            train_loss, train_acc = train_transformer(model_trans, dataloader_f2e, optimizer_trans, criterion_trans)\n",
        "            val_loss, val_acc = evaluate_transformer(model_trans, dataloader_f2e, criterion_trans)\n",
        "        trans_results[f\"layers{num_layers}_heads{nhead}\"] = (val_loss, val_acc)\n",
        "        if val_acc > best_trans_acc:\n",
        "            best_trans_acc = val_acc\n",
        "            best_trans_model = model_trans\n",
        "        print(f\"Config layers={num_layers}, heads={nhead}: Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
        "print(\"=== Transformer French-to-English Translation Test ===\")\n",
        "for sentence in test_french_sentences:\n",
        "    print(f\"\\nInput: {sentence}\")\n",
        "    output = translate_sentence_transformer(best_trans_model, sentence, french_vocab, english_vocab)\n",
        "    print(f\"Output: {output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPPwuMGiOzWM",
        "outputId": "fac05853-8a1d-4934-c3db-c4054d0bb986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "=== RNN Seq2Seq French-to-English ===\n",
            "Epoch 1: Train Loss = 4.5612, Train Acc = 0.2584, Val Loss = 3.4862, Val Acc = 0.3796\n",
            "Epoch 2: Train Loss = 3.2736, Train Acc = 0.4103, Val Loss = 2.8057, Val Acc = 0.4403\n",
            "Epoch 3: Train Loss = 2.6080, Train Acc = 0.4771, Val Loss = 2.0664, Val Acc = 0.5617\n",
            "Epoch 4: Train Loss = 2.0560, Train Acc = 0.5283, Val Loss = 1.3633, Val Acc = 0.7605\n",
            "Epoch 5: Train Loss = 1.2675, Train Acc = 0.7682, Val Loss = 0.7492, Val Acc = 0.9156\n",
            "Epoch 6: Train Loss = 0.6652, Train Acc = 0.9123, Val Loss = 0.3172, Val Acc = 0.9645\n",
            "Epoch 7: Train Loss = 0.3352, Train Acc = 0.9524, Val Loss = 0.1847, Val Acc = 0.9793\n",
            "Epoch 8: Train Loss = 0.1391, Train Acc = 0.9861, Val Loss = 0.0668, Val Acc = 0.9939\n",
            "Epoch 9: Train Loss = 0.0654, Train Acc = 0.9906, Val Loss = 0.0348, Val Acc = 0.9983\n",
            "Epoch 10: Train Loss = 0.0393, Train Acc = 0.9954, Val Loss = 0.0223, Val Acc = 1.0000\n",
            "=== RNN Seq2Seq French-to-English Translation Test ===\n",
            "\n",
            "Input: elle porte une robe rouge et danse à la fête\n",
            "Output: she dances at the party\n",
            "\n",
            "Input: après avoir visité le musée, ils jouent aux jeux vidéo\n",
            "Output: they play video games\n",
            "\n",
            "Input: bien qu'il soit fatigué, il travaille dur tous les jours\n",
            "Output: he works hard every day\n",
            "\n",
            "Input: elle chante une chanson en cuisinant le dîner\n",
            "Output: she catches the bus\n",
            "\n",
            "Input: nous prenons le petit déjeuner ensemble avant d'aller à la salle de sport\n",
            "Output: the stars twinkle at night\n",
            "=== Transformer Seq2Seq French-to-English Experiments ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config layers=1, heads=2: Val Loss = 0.4986, Val Acc = 0.8872\n",
            "Config layers=1, heads=4: Val Loss = 0.5234, Val Acc = 0.9096\n",
            "Config layers=2, heads=2: Val Loss = 2.2139, Val Acc = 0.4544\n",
            "Config layers=2, heads=4: Val Loss = 1.8115, Val Acc = 0.5283\n",
            "Config layers=4, heads=2: Val Loss = 4.3842, Val Acc = 0.1881\n",
            "Config layers=4, heads=4: Val Loss = 4.1699, Val Acc = 0.1879\n",
            "=== Transformer French-to-English Translation Test ===\n",
            "\n",
            "Input: elle porte une robe rouge et danse à la fête\n",
            "Output: she catches at the party\n",
            "\n",
            "Input: après avoir visité le musée, ils jouent aux jeux vidéo\n",
            "Output: they play soccer every weekend\n",
            "\n",
            "Input: bien qu'il soit fatigué, il travaille dur tous les jours\n",
            "Output: he works hard every day\n",
            "\n",
            "Input: elle chante une chanson en cuisinant le dîner\n",
            "Output: she sings in the bus in the bus in the bus in the bus in the bus in the bus\n",
            "\n",
            "Input: nous prenons le petit déjeuner ensemble avant d'aller à la salle de sport\n",
            "Output: we practice yoga\n"
          ]
        }
      ]
    }
  ]
}